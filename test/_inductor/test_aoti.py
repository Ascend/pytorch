# -*- coding: utf-8 -*-
# Copyright (c) Huawei Technologies Co., Ltd. 2023-2023. All rights reserved.
import os
import re
import logging
import tempfile
from pathlib import Path

import torch
from torch.testing._internal.common_utils import run_tests, parametrize, instantiate_parametrized_tests
from torch._inductor import config
import pytest
from testutils import OperatorType, TestUtils
import torch_npu


class TestAotiNpu(TestUtils):
    @parametrize('shape_x', [(32, 512, 64)])
    @parametrize('shape_y', [(32, 1, 64)])
    @parametrize('dtype', ['float32'])
    def test_aoti_compile_and_package(self, shape_x, shape_y, dtype):
        class Model(torch.nn.Module):
            def forward(self, x, y):
                z = x + y
                z = z.repeat([256, 1, 1])
                return z

        example_inputs = (
            self._generate_tensor(shape_x, dtype),
            self._generate_tensor(shape_y, dtype),
        )
        model = Model()

        exported = torch.export.export(
            model,
            example_inputs,
            {},
            strict=False,
        )
        output_path = torch._inductor.aoti_compile_and_package(
            exported,
            package_path=os.path.join(os.getcwd(), f"model_{os.getpid()}.pt2"),
        )
        self.assertTrue(
            os.path.exists(output_path), 
            f"could not find target {output_path} generated by aoti_compile_and_package",
        )


instantiate_parametrized_tests(TestAotiNpu)

if __name__ == "__main__":
    run_tests()