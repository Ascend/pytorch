# 算子迁移和开发指南
## npu_native_functions.yaml文件介绍
```
backend: NPU     # Backend类型
cpp_namespace: at_npu::native     # 插件中开发算子的命名空间
supported:     # 已支持的和PyTorch Native Functions对齐的算子
  - add.Tensor
  - add.Scalar
  - slow_conv3d.out
  - slow_conv3d_forward.output
  - slow_conv3d_forward
  - convolution
  - _convolution
  - _convolution_nogroup
  - addcdiv
  - addcdiv_
  - addcdiv.out

autograd:       # 已支持的和PyTorch Native Functions对齐的继承自Function的具有前反向操作的算子
  - maxpool2d

custom:     # 自定义算子，需要提供算子格式定义
  - func: npu_dtype_cast(Tensor self, ScalarType dtype) -> Tensor
    variants: function, method
  - func: npu_dtype_cast_(Tensor(a!) self, Tensor src) -> Tensor(a!)
    variants: method
  - func: npu_alloc_float_status(Tensor self) -> Tensor
    variants: function, method
  - func: npu_get_float_status(Tensor self) -> Tensor
    variants: function, method
 
custom_autograd:    # 自定义继承自Function的自定义算子
  - func: npu_convolution(Tensor input, Tensor weight, Tensor? bias, ...) -> Tensor
```
官方提供的native_functions.yaml文件定义了PyTorch Native Functions的具体算子定义和分发细节，在NPU设备上适配官方已定义算子，我们不需要重新定义，只需要注册NPU分发即可。由于我们可以根据已支持的算子（supported，autograd）对应解析官方yaml文件得到每个函数的具体格式，所以对应的函数声明和注册分发可以自动化完成，算子迁移和开发的时候只需要关注对应的实现细节即可。对于自定义算子，由于没有具体的算子定义，我们需要在npu_native_functions.yaml文件中给出定义，以便对算子进行结构化解析从而实现自动化注册和Python接口绑定。

## NPU适配算子迁移

#### 拷贝算子实现文件
以Div算子为例，如下是已适配文件
```
// 需要修改为依赖插件的对应头文件
#include "ATen/native/npu/utils/OpAdapter.h"
#include "ATen/native/npu/utils/CalcuOpUtil.h"

// 命名空间需要调整为at_npu::native
namespace at {
namespace native {
using namespace at::native::npu;

// 对应函数名需要调整为何PyTorch官方定义一致，前面加NPUNativeFunctions命名空间约束
Tensor& div_scalar_out_npu(const Tensor& self, const Scalar other, Tensor& result) {
  auto unified_result = OpPreparation::binary_op_check(result, self, other, true);
  OpCommand cmd;
  cmd.Name("Div")
        .Expect(unified_result)
        .Input(self)
        .Input(other, self.scalar_type())
        .Output(result)
        .Run();

  return result;
}

Tensor& div_out_npu_nocheck(const Tensor& self, const Tensor& other, Tensor& result) {

  // executing the NPU operator
  if (other.dim() == 0) {
    div_scalar_out_npu(self, other.item(), result);
  } else {
    auto unified_result = OpPreparation::binary_op_check(result, self, other, true);
    OpCommand cmd;
    cmd.Name("Div")
        .Expect(unified_result)
        .Input(self)
        .Input(other)
        .Output(result)
        .Run();
  }

  return result;
}

// 对应函数名需要调整为何PyTorch官方定义一致，前面加NPUNativeFunctions命名空间约束
Tensor& div_out_npu(const Tensor& self, const Tensor& other, Tensor& result) {
  // calculate the output size
  Tensor outputTensor = CalcuOpUtil::is_scalar_wrapped_to_tensor(self) ? other : self;
  auto outputSize = broadcast_ops_npu_output_size(self, other);
  OpPreparation::CheckOut(
      {self},
      result,
      CalcuOpUtil::get_tensor_npu_format(outputTensor),
      self.scalar_type(),
      outputSize);
  div_out_npu_nocheck(self, other, result);

  return result;
}

// 对应函数名需要调整为何PyTorch官方定义一致，前面加NPUNativeFunctions命名空间约束
Tensor div_npu(const Tensor& self, const Tensor& other) {
  // calculate the output size
  bool isSelfWrapped = CalcuOpUtil::is_scalar_wrapped_to_tensor(self);
  Tensor outputTensor = isSelfWrapped ? other : self;

  auto outputSize = broadcast_ops_npu_output_size(self, other);

  // construct the output tensor of the NPU
  Tensor result = at::empty_with_format(
      outputSize,
      outputTensor.options(),
      CalcuOpUtil::get_tensor_npu_format(outputTensor));

  // calculate the output result of the NPU
  div_out_npu_nocheck(self, other, result);

  return result;
}

// 对应函数名需要调整为何PyTorch官方定义一致，前面加NPUNativeFunctions命名空间约束
Tensor div_scalar_npu(const Tensor& self, Scalar other) {
  // calculate the output size
  auto outputSize = input_same_output_size(self);

  // construct the output tensor of the NPU
  Tensor result = at::empty_with_format(
      outputSize,
      self.options(),
      CalcuOpUtil::get_tensor_npu_format(self));

  // calculate the output result of the NPU
  div_scalar_out_npu(self, other, result);

  return result;
}

// 对应函数名需要调整为何PyTorch官方定义一致，前面加NPUNativeFunctions命名空间约束
Tensor& div_npu_(Tensor& self, const Tensor& other) {
  SmallVector<Tensor, N> inputs = {self, other};
  SmallVector<Tensor, N> outputs = {self};
  CalcuOpUtil::check_memory_over_laps(inputs, outputs);

  if (!NpuUtils::check_match(&self)) {
    Tensor contiguousSelf = NpuUtils::format_contiguous(self);
    Tensor result = div_out_npu_nocheck(contiguousSelf, other, contiguousSelf);
    NpuUtils::format_fresh_view(self, result);
  } else {
    div_out_npu_nocheck(self, other, self);
  }

  return self;
}

// 对应函数名需要调整为何PyTorch官方定义一致，前面加NPUNativeFunctions命名空间约束
Tensor& div_scalar_npu_(Tensor& self, Scalar other) {
  if (!NpuUtils::check_match(&self)) {
    Tensor contiguousSelf = NpuUtils::format_contiguous(self);

    div_scalar_out_npu(contiguousSelf, other, contiguousSelf);

    NpuUtils::format_fresh_view(self, contiguousSelf);
  } else {
    div_scalar_out_npu(self, other, self);
  }
  return self;
}

// 这部分可以删除，将相关的keys添加到npu_native_functions.yaml文件的对应位置，自动化注册
TORCH_LIBRARY_IMPL(aten, NPU, m) {
  m.impl("div.Tensor", TORCH_FN(div_npu));
  m.impl("div_.Tensor", TORCH_FN(div_npu_));
  m.impl("div.out", TORCH_FN(div_out_npu));
  m.impl("div.Scalar", TORCH_FN(div_scalar_npu));
  m.impl("div_.Scalar", TORCH_FN(div_scalar_npu_));
}
} // namespace native
} // namespace at
```

#### 调整函数和对象依赖，编译通过
首先将对应的算子添加到npu_native_functions.yaml文件的对应位置，用于自动化声明和注册。
```
...
supported:     # 已支持的和PyTorch Native Functions对齐的算子
  - div.Tensor
  - div_.Tensor
  - div.out
  - div.Scalar
  - div_.Scalar
  ...
```
算子插件化迁移重构最主要的是需要调整函数命名，除了自定义算子之外，要保持和PyTorch官方的命名保持一致，包括函数重载。除此之外，算子实现迁移到插件，对应的依赖的对象和函数的命名空间需要补齐，否则编译会因为找不到对应的实现而失败。
```
at::Tensor
at::Scalar
at::ScalarType
at::IntArrayRef
at::kFloat
at::Reduction
at::DimnameList
c10::optional
c10::SmallVector

# 后续会迁移到插件，需要注意
c10::NPUStorageDesc
```
重构修改之后的文件如下
```
#include "torch_npu/csrc/framework/utils/OpAdapter.h"
#include "torch_npu/csrc/framework/utils/CalcuOpUtil.h"
#include "torch_npu/csrc/aten/NPUNativeFunctions.h"

namespace at_npu {
namespace native {

at::Tensor& div_scalar_out_npu(const at::Tensor& self, const at::Scalar other, at::Tensor& result) {
  auto unified_result = OpPreparation::binary_op_check(result, self, other, true);
  OpCommand cmd;
  cmd.Name("Div")
        .Expect(unified_result)
        .Input(self)
        .Input(other, self.scalar_type())
        .Output(result)
        .Run();

  return result;
}

at::Tensor& div_out_npu_nocheck(const at::Tensor& self, const at::Tensor& other, at::Tensor& result) {

  // executing the NPU operator
  if (other.dim() == 0) {
    div_scalar_out_npu(self, other.item(), result);
  } else {
    auto unified_result = OpPreparation::binary_op_check(result, self, other, true);
    OpCommand cmd;
    cmd.Name("Div")
        .Expect(unified_result)
        .Input(self)
        .Input(other)
        .Output(result)
        .Run();
  }

  return result;
}

at::Tensor& NPUNativeFunctions::div_out(const at::Tensor& self, const at::Tensor& other, at::Tensor& result) {
  // calculate the output size
  at::Tensor outputTensor = CalcuOpUtil::is_scalar_wrapped_to_tensor(self) ? other : self;
  auto outputSize = broadcast_ops_npu_output_size(self, other);
  OpPreparation::CheckOut(
      {self},
      result,
      CalcuOpUtil::get_tensor_npu_format(outputTensor),
      self.scalar_type(),
      outputSize);
  div_out_npu_nocheck(self, other, result);

  return result;
}

at::Tensor NPUNativeFunctions::div(const at::Tensor& self, const at::Tensor& other) {
  // calculate the output size
  bool isSelfWrapped = CalcuOpUtil::is_scalar_wrapped_to_tensor(self);
  at::Tensor outputTensor = isSelfWrapped ? other : self;

  auto outputSize = broadcast_ops_npu_output_size(self, other);

  // construct the output tensor of the NPU
  at::Tensor result = at::empty_with_format(
      outputSize,
      outputTensor.options(),
      CalcuOpUtil::get_tensor_npu_format(outputTensor));

  // calculate the output result of the NPU
  div_out_npu_nocheck(self, other, result);

  return result;
}

at::Tensor NPUNativeFunctions::div(const at::Tensor& self, at::Scalar other) {
  // calculate the output size
  auto outputSize = input_same_output_size(self);

  // construct the output tensor of the NPU
  at::Tensor result = at::empty_with_format(
      outputSize,
      self.options(),
      CalcuOpUtil::get_tensor_npu_format(self));

  // calculate the output result of the NPU
  div_scalar_out_npu(self, other, result);

  return result;
}

at::Tensor& NPUNativeFunctions::div_(at::Tensor& self, const at::Tensor& other) {
  c10::SmallVector<at::Tensor, N> inputs = {self, other};
  c10::SmallVector<at::Tensor, N> outputs = {self};
  CalcuOpUtil::check_memory_over_laps(inputs, outputs);

  if (!NpuUtils::check_match(&self)) {
    at::Tensor contiguousSelf = NpuUtils::format_contiguous(self);
    at::Tensor result = div_out_npu_nocheck(contiguousSelf, other, contiguousSelf);
    NpuUtils::format_fresh_view(self, result);
  } else {
    div_out_npu_nocheck(self, other, self);
  }

  return self;
}

at::Tensor& NPUNativeFunctions::div_(at::Tensor& self, at::Scalar other) {
  if (!NpuUtils::check_match(&self)) {
    at::Tensor contiguousSelf = NpuUtils::format_contiguous(self);

    div_scalar_out_npu(contiguousSelf, other, contiguousSelf);

    NpuUtils::format_fresh_view(self, contiguousSelf);
  } else {
    div_scalar_out_npu(self, other, self);
  }
  return self;
}

} // namespace native
} // namespace at_npu
```
头文件"torch_npu/csrc/aten/NPUNativeFunctions.h"是根据yaml文件自动生成的算子声明文件，NPUNativeFunctions也是算子定义需要添加的命名空间约束。

#### 迁移测试用例，保证测试通过
对于测试用例的修改，主要注意两点，首先是需要导入插件包torch_npu，功能调用方式基本上维持不变, 除了自定义功能和算子。
```
import torch_npu
```
然后是测试公共层已经剥离到插件包，需要修改对应的导入方式
```
from torch_npu.testing.common_utils import TestCase, run_tests
from torch_npu.testing.common_device_type import Dtypes, instantiate_device_type_tests
from torch_npu.testing.util_test import create_common_tensor, test_2args_broadcast, create_dtype_tensor, UT_FAST_MODE
```

修改之后的测试用例如下：
```
import torch
import torch_npu
import numpy as np
import unittest

from torch_npu.testing.common_utils import TestCase, run_tests
from torch_npu.testing.common_device_type import Dtypes, instantiate_device_type_tests
from torch_npu.testing.util_test import create_common_tensor, test_2args_broadcast, create_dtype_tensor, UT_FAST_MODE


class TestDiv(TestCase):
    def get_outputs(self, cpu_args, npu_args, dtype):
        # cpu not support fp16 div
        cpu_args = [i.float() if dtype == torch.half else i for i in cpu_args]
        cpu_output = torch.div(cpu_args[0], cpu_args[1]).to(dtype).numpy()
        npu_output = torch.div(npu_args[0], npu_args[1]).to("cpu").numpy()
        return cpu_output, npu_output
    
    def get_outputs_chk(self, cpu_args, npu_args, dtype):
        # cpu not support fp16 div
        cpu_out = torch.randn(6).to(dtype)
        npu_out = torch.randn(6).to("npu").to(dtype)
        cpu_args = [i.float() if dtype == torch.half else i for i in cpu_args]
        torch.div(cpu_args[0], cpu_args[1], out = cpu_out)
        torch.div(npu_args[0], npu_args[1], out = npu_out)
        cpu_output = cpu_out.to(dtype).numpy()
        npu_output = npu_out.to("cpu").numpy()
        return cpu_output, npu_output

    def test_div_broadcast(self, device):
        for item in test_2args_broadcast(torch.div):
            self.assertRtolEqual(item[0], item[1])

    # div not support bool
    @Dtypes(torch.float, torch.half, torch.int)
    def test_div_dtype(self, device, dtype):
        cpu_input1, npu_input1 = create_dtype_tensor((2,3,4,5), dtype)
        # divisor can not be zero
        cpu_input2, npu_input2 = create_dtype_tensor((2,3,4,5), dtype, no_zero=True)
        cpu_output, npu_output = self.get_outputs([cpu_input1, cpu_input2], [npu_input1, npu_input2], dtype)

        # div 在int结果为负数时采用截断而不是向下取整的方式取整，所以选用numpy比较
        if dtype == torch.int:
            cpu_output = np.floor_divide(cpu_input1.numpy(), cpu_input2.numpy())

        self.assertRtolEqual(cpu_output, npu_output)
        
    @unittest.skipIf(UT_FAST_MODE, "Run UT in fast mode")
    def test_div_shape_format_fp16(self, device):
        format_list = [0, 3, 29]
        shape_list = [1, (64, 10), (32, 3, 3), (256, 2048, 7, 7)]
        shape_format = [
            [np.float16, i, j] for i in format_list for j in shape_list
        ]
        for item in shape_format:
            cpu_input1, npu_input1 = create_common_tensor(item, 1, 100)
            cpu_input2, npu_input2 = create_common_tensor(item, 1, 100)
            cpu_input1 = cpu_input1.to(torch.float32)
            cpu_input2 = cpu_input2.to(torch.float32)
            cpu_output, npu_output = self.get_outputs([cpu_input1, cpu_input2], [npu_input1, npu_input2], torch.half)
            self.assertRtolEqual(cpu_output, npu_output)

    @unittest.skipIf(UT_FAST_MODE, "Run UT in fast mode")
    def test_div_shape_format_fp32(self, device):
        format_list = [0, 3, 29]
        shape_list = [1, (64, 10), (32, 3, 3), (256, 2048, 7, 7), (2, 0, 2)]
        shape_format = [
            [np.float32, i, j] for i in format_list for j in shape_list
        ]
        for item in shape_format:
            cpu_input1, npu_input1 = create_common_tensor(item, 1, 100)
            cpu_input2, npu_input2 = create_common_tensor(item, 1, 100)
            cpu_output, npu_output = self.get_outputs([cpu_input1, cpu_input2], [npu_input1, npu_input2], torch.float)
            self.assertRtolEqual(cpu_output, npu_output)

    def test_div_mix_dtype_1(self, device):
        npu_input1, npu_input2 = create_common_tensor([np.int32, 0, (2, 3)], 1, 100)
        npu_input3, npu_input4 = create_common_tensor([np.float32, 0, (2, 3)], 1, 100)
        cpu_output, npu_output = self.get_outputs([npu_input1, npu_input3], [npu_input2, npu_input4], torch.float)
        self.assertRtolEqual(cpu_output, npu_output)
        
    def test_div_mix_dtype_2(self, device):
        npu_input1, npu_input2 = create_common_tensor([np.float32, 0, (2, 3)], 1, 100)
        npu_input3 = torch.tensor(3).int()
        cpu_output, npu_output = self.get_outputs([npu_input1, npu_input3], [npu_input2, npu_input3], torch.float)
        self.assertRtolEqual(cpu_output, npu_output)
    
    def test_div_scalar_dtype(self, device):
        cpu_input1, npu_input1 = create_common_tensor([np.int32, 0, (2, 3)], 1, 100)
        cpu_output = cpu_input1 / 0.5
        npu_output = npu_input1 / 0.5
        self.assertRtolEqual(cpu_output, npu_output.cpu())

    def test_div_npuscalar_dtype(self, device):
        cpu_input1, npu_input1 = create_common_tensor([np.int32, 0, (2, 3)], 1, 100)
        cpu_output = cpu_input1 / torch.tensor(0.5)
        npu_output = npu_input1 / torch.tensor(0.5).npu()
        self.assertRtolEqual(cpu_output, npu_output.cpu())
        
    @unittest.skipIf(UT_FAST_MODE, "Run UT in fast mode")
    def test_div_shape_format_fp32(self, device):
        format_list = [0, 3, 29]
        shape_list = [1, (64, 10), (32, 3, 3), (256, 2048, 7, 7)]
        shape_format = [
            [np.float32, i, j] for i in format_list for j in shape_list
        ]
        for item in shape_format:
            cpu_input1, npu_input1 = create_common_tensor(item, 1, 100)
            cpu_input2, npu_input2 = create_common_tensor(item, 1, 100)
            cpu_output, npu_output = self.get_outputs_chk([cpu_input1, cpu_input2], [npu_input1, npu_input2], torch.float)
            self.assertRtolEqual(cpu_output, npu_output)

instantiate_device_type_tests(TestDiv, globals(), except_for="cpu")
if __name__ == "__main__":
    run_tests()
```

## NPU算子适配开发
NPU算子适配开发，需要注意按照目前的规则进行适配，适配完成后的代码逻辑和插件化迁移后代码对应的逻辑一样，同时添加测试用例并测试通过。
