# torch.Tensor

> [!NOTE]   
> 若API“是否支持“为“是“，“限制与说明“为“-“，说明此API和原生API支持度保持一致。

|API名称|是否支持|限制与说明|
|--|--|--|
|torch.Tensor|是|-|
|Tensor.T|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.H|是|-|
|Tensor.mT|是|-|
|Tensor.mH|是|-|
|Tensor.new_tensor|是|-|
|Tensor.new_full|是|支持int64|
|Tensor.new_empty|是|支持fp32|
|Tensor.new_ones|是|支持fp32|
|Tensor.new_zeros|是|支持fp32|
|Tensor.is_cuda|是|-|
|Tensor.is_quantized|是|-|
|Tensor.is_meta|是|-|
|Tensor.device|是|-|
|Tensor.grad|是|支持fp32|
|Tensor.ndim|是|支持fp32|
|Tensor.real|是|-|
|Tensor.imag|是|-|
|Tensor.nbytes|是|-|
|Tensor.itemsize|是|-|
|Tensor.abs|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.abs_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.absolute|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.absolute_|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.acos|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool<br>可能回退至CPU执行|
|Tensor.acos_|是|支持fp16，fp32|
|Tensor.arccos|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.arccos_|是|支持fp16，fp32|
|Tensor.add|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.add_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.addbmm|是|支持fp16，fp32|
|Tensor.addbmm_|是|支持fp16，fp32|
|Tensor.addcdiv|是|支持bf16，fp16，fp32，int64<br>int64类型不支持三个tensor同时广播|
|Tensor.addcdiv_|是|<term>Atlas A2 训练系列产品</term>/<term>Atlas A3 训练系列产品</term>：支持bf16，fp16，fp32，fp64<br><term>Atlas 训练系列产品</term>：支持fp16，fp32，fp64<br>int64类型不支持三个tensor同时广播|
|Tensor.addcmul|是|支持fp16，fp32，int64<br>int64类型不支持三个tensor同时广播|
|Tensor.addcmul_|是|<term>Atlas A2 训练系列产品</term>/<term>Atlas A3 训练系列产品</term>：支持bf16，fp16，fp32，fp64，uint8，int8，int32，int64<br><term>Atlas 训练系列产品</term>：支持fp16，fp32，fp64，uint8，int8，int32，int64<br>int64类型不支持三个tensor同时广播|
|Tensor.addmm|是|支持bf16，fp16，fp32|
|Tensor.addmm_|是|支持fp16，fp32|
|Tensor.sspaddmm|否|-|
|Tensor.addmv|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.addmv_|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.addr|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.addr_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.adjoint|是|-|
|Tensor.allclose|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.amax|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.amin|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.aminmax|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.angle|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|Tensor.apply_|是|仅CPU支持|
|Tensor.argmax|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.argmin|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.argsort|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.argwhere|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.asin|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.asin_|是|支持fp16，fp32|
|Tensor.arcsin|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.arcsin_|是|支持fp16，fp32|
|Tensor.as_strided|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.atan|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.atan_|是|支持fp16，fp32|
|Tensor.arctan|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.arctan_|是|支持fp16，fp32|
|Tensor.atan2|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.atan2_|是|支持fp16，fp32<br>可能回退至CPU执行|
|Tensor.arctan2|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.arctan2_|是|支持fp16，fp32|
|Tensor.all|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.any|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.backward|是|支持fp32|
|Tensor.baddbmm|是|支持fp16，fp32|
|Tensor.baddbmm_|是|支持fp16，fp32|
|Tensor.bernoulli|是|支持fp16，fp32<br>可能回退至CPU执行|
|Tensor.bernoulli_|是|可能回退至CPU执行|
|Tensor.bfloat16|是|支持fp16，fp32|
|Tensor.bincount|是|支持uint8，int8，int16，int32，int64<br>weights维度需与input维度一致|
|Tensor.bitwise_not|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_not_|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_and|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_and_|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_or|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_or_|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_xor|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bitwise_xor_|是|支持uint8，int8，int16，int32，int64，bool|
|Tensor.bmm|是|支持bf16，fp16，fp32|
|Tensor.bool|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.byte|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.broadcast_to|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.ceil|是|支持fp16，fp32|
|Tensor.ceil_|是|支持fp16，fp32|
|Tensor.char|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.chunk|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.clamp|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.clamp_|是|可能回退至CPU执行|
|Tensor.clip|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.clip_|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.clone|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.contiguous|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.copy_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>int16不支持5维以上|
|Tensor.conj|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.resolve_conj|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.resolve_neg|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.copysign|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool<br>可能回退至CPU执行|
|Tensor.cos|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.cos_|是|支持bf16，fp16，fp32，complex64，complex128|
|Tensor.cosh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.cosh_|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.count_nonzero|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.cov|是|支持fp16，fp32，int16，int32，int64|
|Tensor.acosh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>可能回退至CPU执行|
|Tensor.acosh_|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.arccosh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.arccosh_|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.cpu|是|-|
|Tensor.cross|是|支持fp16，fp32，uint8，int8，int16，int32，int64，complex64，complex128<br>两个输入的shape要保持一致|
|Tensor.cuda|是|NPU对应接口为Tensor.npu，memory_format仅支持传入torch.contiguous_format|
|Tensor.cummax|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool<br>可能回退至CPU执行|
|Tensor.cummin|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.cumsum|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>支持Named Tensor|
|Tensor.cumsum_|是|支持fp16，fp32，int64，bool|
|Tensor.chalf|否|-|
|Tensor.cfloat|是|-|
|Tensor.cdouble|是|-|
|Tensor.data_ptr|是|支持fp32|
|Tensor.deg2rad|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.dequantize|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.dense_dim|是|-|
|Tensor.detach|是|支持fp32|
|Tensor.detach_|是|支持fp32|
|Tensor.diag|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|Tensor.diag_embed|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.diagflat|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|Tensor.diagonal|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.diagonal_scatter|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.fill_diagonal_|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.diff|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.dim|是|支持fp32|
|Tensor.dim_order|是|-|
|Tensor.dist|是|-|
|Tensor.div|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.div_|是|支持bf16，fp16，fp32，fp64|
|Tensor.divide|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.divide_|是|支持fp16，fp32|
|Tensor.dot|是|支持fp16，fp32|
|Tensor.double|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>当前部分NPU接口暂不支持double类型，出于兼容性考虑默认返回fp32，后续完成支持后将正常返回fp64<br>可能回退至CPU执行|
|Tensor.dsplit|是|支持fp32|
|Tensor.element_size|是|支持fp32|
|Tensor.eq|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.eq_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.equal|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.erf|是|支持fp16，fp32，int64，bool|
|Tensor.erf_|是|支持fp16，fp32|
|Tensor.erfc|是|支持fp16，fp32，int64，bool|
|Tensor.erfc_|是|支持fp16，fp32|
|Tensor.erfinv|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.erfinv_|是|支持bf16，fp16，fp32|
|Tensor.exp|是|支持bf16，fp16，fp32，fp64，int64，bool|
|Tensor.exp_|是|支持bf16，fp16，fp32，complex64，complex128|
|Tensor.expm1|是|支持fp16，fp32，int64，bool|
|Tensor.expm1_|是|支持fp16，fp32|
|Tensor.expand|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.expand_as|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.exponential_|是|支持bf16，fp16，fp32，fp64|
|Tensor.fix|是|支持fp16，fp32|
|Tensor.fix_|是|支持fp16，fp32|
|Tensor.fill_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.flatten|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.flip|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.fliplr|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.flipud|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.float|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.float_power|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex128|
|Tensor.float_power_|是|支持double|
|Tensor.floor|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.floor_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.floor_divide|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.floor_divide_|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.fmod|是|支持fp16，fp32，uint8，int8，int32，int64|
|Tensor.fmod_|是|支持fp16，fp32，uint8，int8，int32，int64|
|Tensor.frac|是|支持fp16，fp32|
|Tensor.frac_|是|支持fp16，fp32|
|Tensor.gather|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>index维度需与input维度一致|
|Tensor.ge|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.ge_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.greater_equal|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.greater_equal_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.geometric_|是|-|
|Tensor.ger|是|-|
|Tensor.get_device|是|-|
|Tensor.gt|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.gt_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.greater|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.greater_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.half|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.hardshrink|是|支持fp16，fp32|
|Tensor.heaviside|是|可能回退至CPU执行|
|Tensor.histc|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.hsplit|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.index_add_|是|支持fp16，fp32，int64，bool|
|Tensor.index_add|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.index_copy_|是|支持fp16，fp32，int16，int32，bool|
|Tensor.index_copy|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.index_fill_|是|支持fp16，fp32，int32，int64，bool|
|Tensor.index_fill|是|支持bf16，fp16，fp32，int32，int64，bool|
|Tensor.index_put_|是|支持int64|
|Tensor.index_put|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.index_reduce_|是|可能回退至CPU执行|
|Tensor.index_reduce|是|可能回退至CPU执行|
|Tensor.index_select|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.indices|是|-|
|Tensor.inner|是|支持fp16，fp32|
|Tensor.int|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.int_repr|否|-|
|Tensor.isclose|是|支持fp16，fp32，uint8，int32，int64，bool|
|Tensor.isfinite|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.isinf|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.isposinf|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.isneginf|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.isnan|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.is_contiguous|是|支持fp32|
|Tensor.is_complex|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.is_conj|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.is_floating_point|是|支持fp32|
|Tensor.is_inference|是|支持fp32|
|Tensor.is_leaf|是|-|
|Tensor.is_pinned|是|支持fp32|
|Tensor.is_set_to|是|支持fp32|
|Tensor.is_shared|否|-|
|Tensor.is_signed|是|支持fp32|
|Tensor.is_sparse|是|支持fp32|
|Tensor.isreal|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.item|是|支持fp32|
|Tensor.kthvalue|是|支持fp16，fp32，int32|
|Tensor.ldexp|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.ldexp_|是|支持fp16，fp32，complex64，complex128|
|Tensor.le|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.le_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.less_equal|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.less_equal_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.lerp|是|支持fp16，fp32|
|Tensor.lerp_|是|支持fp16，fp32|
|Tensor.log|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.log_|是|支持bf16，fp16，fp32，complex64，complex128|
|Tensor.log10|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.log10_|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.log1p|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.log1p_|是|支持fp16，fp32|
|Tensor.log2|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.log2_|是|支持fp16，fp32，complex64，complex128|
|Tensor.logaddexp|是|支持fp16，fp32，int16，int32，int64，bool|
|Tensor.logaddexp2|是|支持fp16，fp32|
|Tensor.logsumexp|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.logical_and|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.logical_and_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.logical_not|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.logical_not_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.logical_or|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.logical_or_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.logical_xor|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>可能回退至CPU执行|
|Tensor.logical_xor_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.logit|是|支持bf16，fp16，fp32<br>eps取值大于1时输出为nan，eps取值为1时输出为inf|
|Tensor.logit_|是|支持bf16，fp16，fp32<br>eps取值大于1时输出为nan，eps取值为1时输出为inf|
|Tensor.long|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.lt|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.lt_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.less|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.less_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.as_subclass|是|-|
|Tensor.map_|是|仅CPU支持|
|Tensor.masked_scatter_|是|支持fp32，int64，bool|
|Tensor.masked_scatter|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.masked_fill_|是|支持bf16，fp16，fp32，int8，int32，int64，bool|
|Tensor.masked_fill|是|支持bf16，fp16，fp32，int8，int32，int64，bool|
|Tensor.masked_select|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.matmul|是|支持bf16，fp16，fp32<br>支持Named Tensor|
|Tensor.matrix_power|是|支持fp16，fp32|
|Tensor.max|是|支持bf16，fp16，fp32，int64，bool|
|Tensor.maximum|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.mean|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.nanmean|是|支持fp16，fp32|
|Tensor.median|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64<br>input为bf16时，dim不取input轴值为1的维度|
|Tensor.min|是|支持bf16，fp16，fp32，int64，bool|
|Tensor.minimum|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.mm|是|支持bf16，fp16，fp32|
|Tensor.smm|否|-|
|Tensor.mode|否|-|
|Tensor.movedim|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.moveaxis|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.msort|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.mul|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.mul_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.multiply|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.multiply_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.multinomial|是|支持fp16，fp32|
|Tensor.nansum|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.narrow|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.narrow_copy|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.ndimension|是|支持fp32|
|Tensor.nan_to_num|是|-|
|Tensor.nan_to_num_|是|-|
|Tensor.ne|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.ne_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.not_equal|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>可能回退至CPU执行|
|Tensor.not_equal_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.neg|是|支持bf16，fp16，fp32，int8，int32，int64|
|Tensor.neg_|是|支持bf16，fp16，fp32，int8，int32，int64，complex64，complex128<br>可能回退至CPU执行|
|Tensor.negative|是|支持fp16，fp32，int8，int32，int64，complex64，complex128|
|Tensor.negative_|是|支持fp16，fp32，int8，int32，int64，complex64，complex128|
|Tensor.nelement|是|支持fp32|
|Tensor.nonzero|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>不支持nan场景|
|Tensor.norm|是|支持bf16，fp16，fp32，fp64|
|Tensor.normal_|是|支持bf16，fp16，fp32<br>可能回退至CPU执行|
|Tensor.numel|是|支持fp32|
|Tensor.numpy|是|支持fp32|
|Tensor.outer|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.permute|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.positive|是|支持fp16，fp32，uint8，int8，int16，int32，int64，complex64，complex128|
|Tensor.pow|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.pow_|是|支持bf16，fp16，fp32，fp64，int64|
|Tensor.prod|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.put_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，complex64，complex128|
|Tensor.qscheme|否|-|
|Tensor.quantile|是|-|
|Tensor.rad2deg|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.random_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.ravel|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.reciprocal|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.reciprocal_|是|支持fp16，fp32，complex64，complex128|
|Tensor.record_stream|是|支持fp32|
|Tensor.register_hook|是|支持fp32|
|Tensor.register_post_accumulate_grad_hook|是|-|
|Tensor.remainder|是|支持bf16，fp16，fp32，fp64，int32，int64|
|Tensor.remainder_|是|支持fp16，fp32，int32，int64|
|Tensor.repeat|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.repeat_interleave|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool<br>输入张量在重复后得到输出，输出中元素个数需小于$2^{22}$|
|Tensor.requires_grad|是|-|
|Tensor.requires_grad_|是|支持fp32|
|Tensor.reshape|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.reshape_as|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.resize_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>memory_format仅支持torch.contiguous_format和torch.preserve_format|
|Tensor.resize_as_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>memory_format仅支持torch.contiguous_format和torch.preserve_format|
|Tensor.retain_grad|是|支持fp32|
|Tensor.retains_grad|是|支持fp32|
|Tensor.roll|是|支持bf16，fp16，fp32，uint8，int8，int32，int64，bool|
|Tensor.rot90|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.round|是|支持fp16，fp32|
|Tensor.round_|是|支持fp16，fp32|
|Tensor.rsqrt|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.rsqrt_|是|支持fp16，fp32，complex64，complex128|
|Tensor.scatter|是|支持fp16，fp32，fp64，int8，int16，int32，int64，bool|
|Tensor.scatter_|是|tensor、index、src参数不能为空且不能为scalar<br>可能回退至CPU执行|
|Tensor.scatter_add_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.scatter_add|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.scatter_reduce|是|支持fp32，int64<br>可能回退至CPU执行|
|Tensor.select|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.select_scatter|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool<br>可能回退至CPU执行|
|Tensor.set_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.share_memory_|否|-|
|Tensor.short|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.sigmoid|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.sigmoid_|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.sign|是|支持bf16，fp16，fp32，fp64，int32，int64，bool|
|Tensor.sign_|是|支持fp16，fp32，int32，int64，bool|
|Tensor.sgn|是|支持fp16，fp32，int32，int64，bool，complex64，complex128|
|Tensor.sgn_|是|支持fp16，fp32，fp64，int32，int64，bool|
|Tensor.sin|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.sin_|是|支持bf16，fp16，fp32，complex64，complex128|
|Tensor.sinh|是|支持fp16，fp32，fp64|
|Tensor.sinh_|是|支持fp16，fp32，fp64|
|Tensor.asinh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.asinh_|是|支持fp16，fp32，complex64，complex128|
|Tensor.arcsinh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.arcsinh_|是|支持fp16，fp32，complex64，complex128|
|Tensor.shape|是|-|
|Tensor.size|是|支持fp32|
|Tensor.slogdet|是|支持fp32，complex64，complex128|
|Tensor.slice_scatter|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.softmax||支持fp16，fp16，fp32，fp64|
|Tensor.sort|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.split|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.sparse_mask|否|-|
|Tensor.sparse_dim|是|-|
|Tensor.sqrt|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.sqrt_|是|支持bf16，fp16，fp32，fp64，complex64，complex128|
|Tensor.square|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.square_|是|支持fp16，fp32，uint8，int8，int16，int32，int64，complex64，complex128|
|Tensor.squeeze|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.squeeze_|是|支持fp32|
|Tensor.std|是|支持bf16，fp16，fp32<br>input不支持标量tensor<br>correction不大于int32的范围|
|Tensor.storage|是|支持fp32|
|Tensor.untyped_storage|是|支持fp32|
|Tensor.storage_offset|是|支持fp32|
|Tensor.storage_type|是|支持fp32|
|Tensor.stride|是|支持fp32|
|Tensor.sub|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.sub_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，complex64，complex128|
|Tensor.subtract_|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|Tensor.sum|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.sum_to_size|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.swapaxes|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.swapdims|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.t|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，complex64，complex128|
|Tensor.t_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64|
|Tensor.tensor_split|是|仅CPU支持|
|Tensor.tile|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>若入参dims的长度小于Tensor.shape的长度，则会在dims前自动补全1，使其长度与 Tensor.shape对齐。补全后的dims，需要满足如下限制：<br>- 当需要对第一根轴进行重复时，最多允许同时对4个维度进行重复操作（即dims中大于1的元素个数 ≤ 4），例如：不支持Tensor.tile([2, 3, 4, 5, 6]) ，支持Tensor.tile([2, 3, 1, 5, 6])<br>- 当不需要对第一根轴进行重复时，最多允许同时对3个维度进行重复操作（即dims中大于1的元素个数 ≤ 3），例如：不支持Tensor.tile([1, 3, 4, 5, 6]) ，支持Tensor.tile([1, 3, 1, 5, 6])<br>- 若执行反向计算，Tensor的维度数与入参dims中大于1的元素个数之和不得超过8|
|Tensor.to|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>当前NPU设备仅支持设置memory_format为torch.contiguous_format或torch.preserve_format<br><term>Atlas 推理系列产品</term>不支持跨NPU拷贝|
|to|是|-|
|Tensor.to_mkldnn|否|-|
|Tensor.take|是|支持fp16，fp32，int16，int32，bool|
|Tensor.take_along_dim|是|支持fp16，fp32，int16，int32，int64，bool|
|Tensor.tan|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128取值范围[-65504,65504]|
|Tensor.tan_|是|支持fp16，fp32，complex64，complex128|
|Tensor.tanh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|Tensor.tanh_|是|支持fp16，fp32|
|Tensor.atanh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.atanh_|是|支持fp16，fp32，complex64，complex128|
|Tensor.arctanh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.arctanh_|是|支持fp16，fp32，complex64，complex128|
|Tensor.tolist|是|支持fp32|
|Tensor.topk|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64<br>由于硬件差异，npu topk索引结果与gpu/cpu不一致。当前npu仅支持返回sorted为true的计算结果<br>不支持标量tensor|
|Tensor.to_dense|否|-|
|Tensor.to_sparse|否|-|
|to_sparse|否|-|
|Tensor.to_sparse_csr|否|-|
|Tensor.to_sparse_csc|否|-|
|Tensor.to_sparse_bsr|否|-|
|Tensor.to_sparse_bsc|否|-|
|Tensor.transpose|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.transpose_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.tril|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.tril_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.triu|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.triu_|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.true_divide|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.true_divide_|是|支持fp16，fp32|
|Tensor.trunc|是|支持fp16，fp32|
|Tensor.trunc_|是|支持fp16，fp32|
|Tensor.type|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.type_as|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.unbind|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.unflatten|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.unfold|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|Tensor.uniform_|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64<br>遵循PyTorch社区规范，不再支持对bool类型数据进行处理。针对存量bool类型数据可以通过如下方案进行替换：如果需要输出全True，可以采用Tensor.bernoulli_(p=1.0)。如果需要输出均匀分布的bool类型，则采用Tensor.bernoulli_(p=0.5)|
|Tensor.unique|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>在输入包含0的情况下，输出中可能会包含正0和负0，而非只输出一个0|
|Tensor.unique_consecutive|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.unsqueeze|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.unsqueeze_|是|支持fp32|
|Tensor.values|是|依赖稀疏tensor|
|Tensor.var|是|支持bf16，fp16，fp32<br>correction不大于int32的范围|
|Tensor.view|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|view|是|-|
|Tensor.view_as|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.vsplit|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|Tensor.where|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|Tensor.xlogy|是|支持fp16，fp32|
|Tensor.xlogy_|是|支持fp16，fp32|
|Tensor.zero_|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|

