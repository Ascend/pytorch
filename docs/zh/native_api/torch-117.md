# torch

> [!NOTE]   
> 若API“是否支持“为“是“，“限制与说明“为“-“，说明此API和原生API支持度保持一致。

|API名称|是否支持|限制与说明|
|--|--|--|
|torch.default_generator|是|-|
|torch.SymInt|是|支持fp32|
|torch.SymFloat|是|支持fp32|
|torch.SymBool|是|支持fp32|
|torch.Tag|是|-|
|torch.Tag.name|是|-|
|torch.is_tensor|是|-|
|torch.is_storage|是|-|
|torch.is_complex|是|支持fp32|
|torch.is_conj|是|-|
|torch.is_floating_point|是|支持fp32|
|torch.is_nonzero|是|支持fp32|
|torch.set_default_dtype|是|-|
|torch.get_default_dtype|是|-|
|torch.set_default_device|是|-|
|torch.set_default_tensor_type|是|不支持传入torch.npu.DtypeTensor类型|
|torch.numel|是|-|
|torch.set_printoptions|是|-|
|torch.set_flush_denormal|是|-|
|torch.tensor|是|-|
|torch.sparse_coo_tensor|是|indices支持int32，int64<br>values支持fp16，fp32，int32<br>dtype参数与values的dtype保持一致|
|torch.sparse_csr_tensor|否|-|
|torch.sparse_csc_tensor|否|-|
|torch.sparse_bsr_tensor|否|-|
|torch.sparse_bsc_tensor|否|-|
|torch.asarray|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.as_tensor|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.as_strided|是|支持fp32|
|torch.from_numpy|是|支持输出fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.from_dlpack|否|-|
|torch.frombuffer|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.zeros|是|-|
|torch.zeros_like|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.ones|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.ones_like|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.arange|是|支持bf16，fp16，fp32，fp64，int32，int64|
|torch.range|是|-|
|torch.linspace|是|支持bf16，fp16，fp32，fp64<br>创建序列大小为steps的1维向量|
|torch.eye|是|支持fp16，fp32|
|torch.empty|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.empty_like|是|支持bf16，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.empty_strided|是|-|
|torch.full|是|支持fp32|
|torch.full_like|是|支持uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.quantize_per_tensor|否|-|
|torch.quantize_per_channel|否|-|
|torch.dequantize|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.complex|是|-|
|torch.polar|是|支持fp32<br>入参abs和angle的维度需相等|
|torch.heaviside|否|-|
|torch.argwhere|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.cat|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.concat|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|torch.concatenate|是|支持bf16，fp16，fp32，int64，bool，complex64|
|torch.conj|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.chunk|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.dsplit|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.dstack|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|torch.gather|是|支持fp16，fp32，int16，int32，int64，bool<br>index维度需与input维度一致|
|torch.hsplit|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.hstack|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|torch.index_add|是|支持fp16，fp32，int64，bool|
|torch.index_copy|是|支持fp32|
|torch.index_reduce|是|可能回退至CPU执行|
|torch.index_select|是|支持bf16，fp16，fp32，int16，int32，int64，bool|
|torch.masked_select|是|支持fp16，fp32，int16，int32，int64，bool|
|torch.movedim|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.moveaxis|是|支持torch.int64， torch.float， torch.complex128|
|torch.narrow|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.narrow_copy|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>可能回退至CPU执行|
|torch.nonzero|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.permute|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.reshape|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.row_stack|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|torch.scatter|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>可能回退至CPU执行|
|torch.diagonal_scatter|是|支持bf16，fp16，fp32，int16，int32，int64，bool|
|torch.select_scatter|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.slice_scatter|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.scatter_reduce|否|-|
|torch.split|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.squeeze|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.stack|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.swapaxes|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.swapdims|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.t|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.take|是|支持fp16，fp32，int16，int32，int64，bool|
|torch.take_along_dim|是|支持fp32|
|torch.tensor_split|是|仅CPU支持|
|torch.tile|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>若入参dims的长度小于input.shape的长度，则会在dims前自动补全1，使其长度与 input.shape对齐。补全后的dims，需要满足如下限制：<br>- 当需要对第一根轴进行重复时，最多允许同时对4个维度进行重复操作(即dims中大于1的元素个数 ≤ 4)，例如：不支持torch.tile(input, [2, 3, 4, 5, 6]) ，支持torch.tile(input, [2, 3, 1, 5, 6])<br>- 当不需要对第一根轴进行重复时，最多允许同时对3个维度进行重复操作(即dims中大于1的元素个数 ≤ 3)，例如：不支持torch.tile(input, [1, 3, 4, 5, 6]) ，支持torch.tile(input, [1, 3, 1, 5, 6])<br>- 若执行反向计算，输入Tensor的维度数与入参dims中大于1的元素个数之和不得超过8|
|torch.transpose|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.unsqueeze|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.vsplit|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.vstack|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.where|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>不支持8维度的shape|
|torch.Generator|是|-|
|torch.Generator.device|是|-|
|torch.Generator.get_state|是|-|
|torch.Generator.initial_seed|是|-|
|torch.Generator.manual_seed|是|-|
|torch.Generator.seed|是|-|
|torch.Generator.set_state|是|-|
|torch.seed|是|-|
|torch.manual_seed|是|-|
|torch.initial_seed|是|-|
|torch.get_rng_state|是|-|
|torch.set_rng_state|是|-|
|torch.bernoulli|是|支持fp32|
|torch.multinomial|是|支持fp16，fp32|
|torch.normal|是|支持fp16，fp32|
|torch.poisson|否|-|
|torch.rand|是|-|
|torch.rand_like|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64<br>遵循PyTorch社区规范，不再支持对bool类型数据进行处理。针对存量bool类型数据可以通过如下方案进行替换：如果需要输出全True，可以采用torch.bernoulli(input, 1)。如果需要输出均匀分布的bool类型，则采用torch.bernoulli(input, 0.5)|
|torch.randint|是|-|
|torch.randint_like|是|支持fp16，fp32，int64|
|torch.randn|是|-|
|torch.randn_like|是|支持fp32|
|torch.randperm|是|-|
|torch.save|是|-|
|torch.load|是|-|
|torch.get_num_threads|是|-|
|torch.set_num_threads|是|-|
|torch.get_num_interop_threads|是|-|
|torch.set_num_interop_threads|是|-|
|torch.no_grad|是|-|
|torch.enable_grad|是|-|
|torch.autograd.grad_mode.set_grad_enabled|是|-|
|torch.is_grad_enabled|是|-|
|torch.autograd.grad_mode.inference_mode|是|-|
|torch.is_inference_mode_enabled|是|-|
|torch.abs|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.absolute|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.acos|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.arccos|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.acosh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>可能回退至CPU执行|
|torch.arccosh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.add|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.addcdiv|是|支持fp16，fp32，int64<br>在int64类型不支持三个tensor同时广播|
|torch.addcmul|是|支持bf16，fp16，fp32，fp64，uint8，int8，int32，int64<br>在fp64，uint8，int8，int64类型不支持三个tensor同时广播|
|torch.angle|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|torch.asin|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.arcsin|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.asinh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.arcsinh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.atan|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.arctan|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.atanh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.arctanh|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.atan2|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.arctan2|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.bitwise_not|是|支持uint8，int8，int16，int32，int64，bool|
|torch.bitwise_and|是|支持uint8，int8，int16，int32，int64，bool|
|torch.bitwise_or|是|支持uint8，int8，int16，int32，int64，bool|
|torch.bitwise_xor|是|支持uint8，int8，int16，int32，int64，bool|
|torch.ceil|是|支持fp16，fp32|
|torch.clamp|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.clip|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.copysign|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool<br>可能回退至CPU执行|
|torch.cos|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.cosh|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.deg2rad|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.div|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.divide|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.erf|是|支持fp16，fp32，int64，bool|
|torch.erfc|是|支持fp16，fp32，int64，bool|
|torch.erfinv|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.exp|是|支持bf16，fp16，fp32，fp64，int64，bool，complex64，complex128|
|torch.exp2|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.expm1|是|支持fp16，fp32，int64，bool|
|torch.fix|是|支持bf16，fp16，fp32|
|torch.float_power|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex128|
|torch.floor|是|支持fp16，fp32|
|torch.floor_divide|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|torch.fmod|是|支持fp16，fp32，uint8，int8，int32，int64|
|torch.gradient|是|支持bf16，fp16，fp32，int8，int16，int32，int64|
|torch.ldexp|是|支持fp16，fp64，complex64|
|torch.lerp|是|支持fp16，fp32|
|torch.log|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.log10|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>当输入input为uint8，int8，int16，int32，int64，bool时，输出out必须为fp32<br>其余支持数据类型输出out和输入input保持一致|
|torch.log1p|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.log2|是|支持bf16，fp32，int64，bool，fp16|
|torch.logaddexp|是|不支持double数据类型|
|torch.logaddexp2|是|不支持double数据类型|
|torch.logical_and|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.logical_not|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.logical_or|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.logical_xor|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.logit|是|支持bf16，fp16，fp32<br>eps取值大于1时输出为nan，eps取值为1时输出为inf|
|torch.mul|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.multiply|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.nan_to_num|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.neg|是|支持bf16，fp16，fp32，int8，int32，int64，complex64，complex128|
|torch.negative|是|支持bf16，fp16，fp32，int8，int32，int64，complex64，complex128|
|torch.positive|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，complex64，complex128|
|torch.pow|是|支持bf16，fp16，fp32，fp64，int16，int64|
|torch.rad2deg|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.real|是|支持fp16，fp32，complex64，complex128|
|torch.reciprocal|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.remainder|是|支持fp16，fp32，int16，int32，int64|
|torch.round|是|支持fp16，fp32|
|torch.rsqrt|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.sigmoid|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.sign|是|支持bf16，fp16，fp32，int32，int64，bool|
|torch.sgn|是|支持bf16，fp16，fp32，int32，int64，bool，complex64，complex128|
|torch.sin|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.sinh|是|支持fp16，fp32，fp64|
|torch.softmax|是|支持fp32<br>支持Named Tensor|
|torch.sqrt|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.square|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|torch.sub|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|torch.tan|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>取值范围[-65504,65504]|
|torch.tanh|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.true_divide|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.trunc|是|支持fp16，fp32<br>可能回退至CPU执行|
|torch.xlogy|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.argmax|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|torch.argmin|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|torch.amax|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.amin|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.aminmax|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.all|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.any|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.max|是|支持bf16，fp16，fp32，int64，bool|
|torch.min|是|支持bf16，fp16，fp32，int64，bool|
|torch.dist|是|支持bf16，fp16，fp32|
|torch.logsumexp|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.mean|是|支持bf16，fp16，fp32，complex64，complex128|
|torch.median|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.norm|是|支持bf16，fp16，fp32<br>参数p为负数时，计算结果可能存在精度误差<br>参数dim指定为输入tensor中shape维度值为1的轴时，计算结果可能存在精度误差|
|torch.nansum|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.prod|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.nanquantile|否|-|
|torch.std|是|支持fp16，fp32<br>可能回退至CPU执行|
|torch.std_mean|否|-|
|torch.sum|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool<br>不支持dtype参数|
|torch.unique|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool<br>带dim场景不支持fp16<br>在输入包含0的情况下，输出中可能会包含正0和负0，而非只输出一个0|
|torch.unique_consecutive|否|-|
|torch.var|是|支持fp16，fp32|
|torch.var_mean|否|-|
|torch.count_nonzero|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.allclose|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.argsort|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|torch.eq|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.equal|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.ge|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.greater_equal|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.gt|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.greater|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.isclose|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.isfinite|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.isin|是|双tensor输入的场景约束如下：<br>- 支持fp16，fp32，uint8，int8，int16，int32，int64<br>- 第一个输入tensor维度不能大于7维，第二个输入tensor维度不能大于8维<br>单tensor输入的场景约束如下：<br>- 支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64<br>- 输入tensor的维度不大于8维|
|torch.isinf|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.isposinf|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.isneginf|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.isnan|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.kthvalue|是|支持fp16，fp32，int32|
|torch.le|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.less_equal|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|torch.lt|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.less|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.maximum|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.minimum|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.ne|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.not_equal|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.sort|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|torch.topk|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64不支持sorted=False场景|
|torch.msort|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.stft|是|若算子超时，需要用官方接口set_op_execute_time_out进行设置，调高超时阈值判断时间|
|torch.hann_window|是|支持bf16，fp16，fp32<br>数据类型为fp32时，参数window_length在大于10000的情况下，计算结果可能存在误差|
|torch.atleast_1d|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.atleast_2d|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.atleast_3d|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.bincount|是|支持uint8，int8，int16，int32，int64<br>weights维度需与input维度一致|
|torch.block_diag|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.broadcast_tensors|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.broadcast_to|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.broadcast_shapes|是|-|
|torch.cdist|否|-|
|torch.clone|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.combinations|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.cov|是|支持fp32|
|torch.cross|是|支持fp16，fp32，uint8，int8，int16，int32，int64，complex64，complex128<br>两个输入的shape要保持一致|
|torch.cummax|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.cummin|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool<br>输入为int32时，数值范围在[-16777216, 16777216]内|
|torch.cumprod|是|支持fp16，fp32，int32|
|torch.cumsum|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128<br>支持Named Tensor|
|torch.diag|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64|
|torch.diag_embed|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.diagonal|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.diff|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.einsum|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.flatten|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.flip|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.fliplr|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.flipud|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.kron|是|不支持5维度及以上输入|
|torch.histc|是|支持fp16，fp32<br>当输入tensor值处于计数区间交界时，归于左区间计数还是右区间计数可能存在误差|
|torch.meshgrid|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.ravel|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.repeat_interleave|是|支持fp16，fp32，int16，int32，int64，bool<br>输入张量在重复后得到输出，输出中元素个数需小于$2^{22}$|
|torch.roll|是|支持fp16，fp32，int32，int64，bool|
|torch.searchsorted|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|torch.tensordot|是|支持fp16，fp32|
|torch.tril|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.tril_indices|是|-|
|torch.triu|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.triu_indices|是|-|
|torch.unflatten|是|-|
|torch.view_as_real|是|支持complex64|
|torch.view_as_complex|是|支持fp32，fp64|
|torch.resolve_conj|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.resolve_neg|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64，bool，complex64，complex128|
|torch.addbmm|是|支持fp16，fp32|
|torch.addmm|是|支持fp16，fp32|
|torch.addmv|是|支持fp16，fp32，uint8，int8，int16，int32，int64|
|torch.addr|是|支持fp16，fp32，uint8，int8，int16，int32，int64，bool|
|torch.baddbmm|是|支持fp16，fp32|
|torch.bmm|是|支持fp16，fp32|
|torch.dot|是|支持fp16，fp32|
|torch.slogdet|是|支持fp32，complex64，complex128<br>可能回退至CPU执行|
|torch.matmul|是|支持fp16，fp32<br>支持Named Tensor<br>输入最大支持6维|
|torch.mm|是|支持fp16，fp32|
|torch.outer|是|支持bf16，fp16，fp32，fp64，uint8，int8，int16，int32，int64，bool|
|torch.qr|是|-|
|torch.trapezoid|是|支持bf16，fp16，fp32，uint8，int8，int16，int32，int64|
|torch.cumulative_trapezoid|是|支持fp16，fp32，fp64，uint8，int8，int16，int32，int64|
|torch.vdot|是|支持fp16，fp32|
|torch.compiled_with_cxx11_abi|是|-|
|torch.result_type|是|支持fp32|
|torch.can_cast|是|-|
|torch.promote_types|是|-|
|torch.use_deterministic_algorithms|是|同时设置HCCL_DETTERMINISTIC和torch.use_deterministic_algorithms时，若HCCL_DETTERMINISTIC开启确定性则hccl接口启用确定性，否则hccl确定性由torch.use_deterministic_algorithms接口控制|
|torch.are_deterministic_algorithms_enabled|是|-|
|torch.is_deterministic_algorithms_warn_only_enabled|否|-|
|torch.set_deterministic_debug_mode|是|-|
|torch.get_deterministic_debug_mode|是|-|
|torch.set_float32_matmul_precision|是|-|
|torch.get_float32_matmul_precision|是|-|
|torch.set_warn_always|是|-|
|torch.is_warn_always_enabled|是|-|
|torch.vmap|是|-|
|torch._assert|是|-|
|torch.sym_float|是|支持fp32|
|torch.sym_int|是|支持fp32|
|torch.sym_max|是|支持fp32|
|torch.sym_min|是|支持fp32|
|torch.sym_not|是|支持fp32|
|torch.compile|是|backend可支持npugraphs，整体功能与backend="cudagraphs"一致|


