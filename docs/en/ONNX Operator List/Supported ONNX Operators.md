# Supported ONNX Operators
-   [Abs](#Absmd)
-   [Acos](#Acosmd)
-   [Acosh](#Acoshmd)
-   [AdaptiveAvgPool2D](#AdaptiveAvgPool2Dmd)
-   [AdaptiveMaxPool2D](#AdaptiveMaxPool2Dmd)
-   [Add](#Addmd)
-   [Addcmul](#Addcmulmd)
-   [AffineGrid](#AffineGridmd)
-   [And](#Andmd)
-   [Argmax](#Argmaxmd)
-   [Argmin](#Argminmd)
-   [AscendRequantS16](#AscendRequantS16md)
-   [AscendRequant](#AscendRequantmd)
-   [AscendQuant](#AscendQuantmd)
-   [AscendDequantS16](#AscendDequantS16md)
-   [AscendDequant](#AscendDequantmd)
-   [AscendAntiQuant](#AscendAntiQuantmd)
-   [Asin](#Asinmd)
-   [Asinh](#Asinhmd)
-   [Atan](#Atanmd)
-   [Atanh](#Atanhmd)
-   [AveragePool](#AveragePoolmd)
-   [BatchNormalization](#BatchNormalizationmd)
-   [BatchMatMul](#BatchMatMulmd)
-   [BatchMultiClassNMS](#BatchMultiClassNMSmd)
-   [BitShift](#BitShiftmd)
-   [Cast](#Castmd)
-   [Ceil](#Ceilmd)
-   [Celu](#Celumd)
-   [Concat](#Concatmd)
-   [Clip](#Clipmd)
-   [ConvTranspose](#ConvTransposemd)
-   [Cumsum](#Cumsummd)
-   [Conv](#Convmd)
-   [Compress](#Compressmd)
-   [Constant](#Constantmd)
-   [ConstantOfShape](#ConstantOfShapemd)
-   [Cos](#Cosmd)
-   [Cosh](#Coshmd)
-   [DeformableConv2D](#DeformableConv2Dmd)
-   [Det](#Detmd)
-   [DepthToSpace](#DepthToSpacemd)
-   [Div](#Divmd)
-   [Dropout](#Dropoutmd)
-   [Elu](#Elumd)
-   [EmbeddingBag](#EmbeddingBagmd)
-   [Equal](#Equalmd)
-   [Erf](#Erfmd)
-   [Exp](#Expmd)
-   [Expand](#Expandmd)
-   [EyeLike](#EyeLikemd)
-   [Flatten](#Flattenmd)
-   [Floor](#Floormd)
-   [Gather](#Gathermd)
-   [GatherND](#GatherNDmd)
-   [GatherElements](#GatherElementsmd)
-   [Gemm](#Gemmmd)
-   [GlobalAveragePool](#GlobalAveragePoolmd)
-   [GlobalLpPool](#GlobalLpPoolmd)
-   [GlobalMaxPool](#GlobalMaxPoolmd)
-   [Greater](#Greatermd)
-   [GreaterOrEqual](#GreaterOrEqualmd)
-   [HardSigmoid](#HardSigmoidmd)
-   [hardmax](#hardmaxmd)
-   [HardSwish](#HardSwishmd)
-   [Identity](#Identitymd)
-   [If](#Ifmd)
-   [InstanceNormalization](#InstanceNormalizationmd)
-   [Less](#Lessmd)
-   [LeakyRelu](#LeakyRelumd)
-   [LessOrEqual](#LessOrEqualmd)
-   [Log](#Logmd)
-   [LogSoftMax](#LogSoftMaxmd)
-   [LpNormalization](#LpNormalizationmd)
-   [LpPool](#LpPoolmd)
-   [LRN](#LRNmd)
-   [LSTM](#LSTMmd)
-   [MatMul](#MatMulmd)
-   [Max](#Maxmd)
-   [MaxPool](#MaxPoolmd)
-   [MaxRoiPool](#MaxRoiPoolmd)
-   [MaxUnpool](#MaxUnpoolmd)
-   [Mean](#Meanmd)
-   [MeanVarianceNormalization](#MeanVarianceNormalizationmd)
-   [Min](#Minmd)
-   [Mod](#Modmd)
-   [Mul](#Mulmd)
-   [Multinomial](#Multinomialmd)
-   [Neg](#Negmd)
-   [NonMaxSuppression](#NonMaxSuppressionmd)
-   [NonZero](#NonZeromd)
-   [Not](#Notmd)
-   [OneHot](#OneHotmd)
-   [Or](#Ormd)
-   [RandomNormalLike](#RandomNormalLikemd)
-   [RandomUniformLike](#RandomUniformLikemd)
-   [RandomUniform](#RandomUniformmd)
-   [Range](#Rangemd)
-   [Reciprocal](#Reciprocalmd)
-   [ReduceL1](#ReduceL1md)
-   [ReduceL2](#ReduceL2md)
-   [ReduceLogSum](#ReduceLogSummd)
-   [ReduceLogSumExp](#ReduceLogSumExpmd)
-   [ReduceMin](#ReduceMinmd)
-   [ReduceMean](#ReduceMeanmd)
-   [ReduceProd](#ReduceProdmd)
-   [ReduceSumSquare](#ReduceSumSquaremd)
-   [Resize](#Resizemd)
-   [Relu](#Relumd)
-   [ReduceSum](#ReduceSummd)
-   [ReduceMax](#ReduceMaxmd)
-   [Reshape](#Reshapemd)
-   [ReverseSequence](#ReverseSequencemd)
-   [RoiExtractor](#RoiExtractormd)
-   [RoiAlign](#RoiAlignmd)
-   [Round](#Roundmd)
-   [PRelu](#PRelumd)
-   [Scatter](#Scattermd)
-   [ScatterElements](#ScatterElementsmd)
-   [ScatterND](#ScatterNDmd)
-   [Shrink](#Shrinkmd)
-   [Selu](#Selumd)
-   [Shape](#Shapemd)
-   [Sigmoid](#Sigmoidmd)
-   [Slice](#Slicemd)
-   [Softmax](#Softmaxmd)
-   [Softsign](#Softsignmd)
-   [Softplus](#Softplusmd)
-   [SpaceToDepth](#SpaceToDepthmd)
-   [Split](#Splitmd)
-   [Sqrt](#Sqrtmd)
-   [Squeeze](#Squeezemd)
-   [Sub](#Submd)
-   [Sign](#Signmd)
-   [Sin](#Sinmd)
-   [Sinh](#Sinhmd)
-   [Size](#Sizemd)
-   [Sum](#Summd)
-   [Tanh](#Tanhmd)
-   [TfIdfVectorizer](#TfIdfVectorizermd)
-   [Tile](#Tilemd)
-   [ThresholdedRelu](#ThresholdedRelumd)
-   [TopK](#TopKmd)
-   [Transpose](#Transposemd)
-   [Pad](#Padmd)
-   [Pow](#Powmd)
-   [Unsqueeze](#Unsqueezemd)
-   [Xor](#Xormd)
-   [Where](#Wheremd)
<h2 id="Absmd">Abs</h2>

### Description 

Computes the absolute value of a tensor.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, double, int32, or int64.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Acosmd">Acos</h2>

### Description

Computes acos of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Acoshmd">Acosh</h2>

### Description

Computes inverse hyperbolic cosine of input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="AdaptiveAvgPool2Dmd">AdaptiveAvgPool2D</h2>

### Description 

Applies a 2D adaptive avg pooling over the input.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Attributes]

One attribute

output\_size: array of ints, specifying the output H and W shape sizes.

[Outputs]

One output

y: tensor of the identical data type as x.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AdaptiveMaxPool2Dmd">AdaptiveMaxPool2D</h2>

### Description

Applies a 2D adaptive max pooling over the input.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or float64.

[Attributes]

One attribute

output\_size: array of ints, specifying the output H and W shape sizes.

[Outputs]

Two outputs

y: tensor of the identical data type as x.

argmax: tensor of type int32 or int64.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="Addmd">Add</h2>

### Description

Adds inputs element-wise.

### Parameters 

[Inputs]

Two inputs

A: tensor. Must be one of the following types: int8, int16, int32, int64, uint8, float32, float16, double.

B: tensor. Has an identical data type to that of A.

[Outputs]

C: tensor. Has an identical data type to that of A.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Addcmulmd">Addcmul</h2>

### Description

Performs element-wise computation: \(x1 \* x2\) \* value + input\_data

### Parameters 

[Inputs]

Four inputs

input\_data: tensor of type float16, float32, int32, int8, or uint8.

x1: tensor of the identical data type as input\_data

x2: tensor of the identical data type as input\_data

value: tensor of the identical data type as input\_data

[Outputs]

One output

y: tensor of the identical data type as the inputs.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AffineGridmd">AffineGrid</h2>

### Description 

Generates a sampling grid with given matrices.

### Parameters 

[Inputs]

Two inputs

theta: tensor of type float16 or float32.

output\_size: tensor of type int32

[Attributes]

One attribute

align\_corners: bool

[Outputs]

One output

y: tensor of type int.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="Andmd">And</h2>

### Description 

Returns the tensor resulted from performing the AND logical operation element-wise on the input tensors.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type bool.

x2: tensor of type bool.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Argmaxmd">Argmax</h2>

### Description 

Returns the indices of the maximum elements along the provided axis.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type int32, the indices. Has the same shape as x with the dimension along axis removed.

[Attributes]

axis: (required) int32, axis in which to compute the arg indices. Accepted range is \[-len\(x.shape\), len\(x.shape\)-1\].

keep\_dim: (optional) either 1 (default) or 0.

[Restrictions]

The operator does not support inputs of type float32 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Argminmd">Argmin</h2>

### Description 

Returns the indices of the minimum values along an axis.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type int64.

[Attributes]

axis: int. Must be in the range [–r, r – 1], where r indicates the rank of the input.

[Restrictions]

The operator does not support inputs of type float32 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="AscendRequantS16md">AscendRequantS16</h2>

### Description 

Performs requantization.

### Parameters 

[Inputs]

Two required inputs and one optional input

x0: tensor of type int16.

req\_scale: tensor of type uint64.

x1: tensor of type int16.

[Attributes]

Two attributes

dual\_output: bool

relu\_flag: bool

[Outputs]

Two outputs

y0: tensor of type int8.

y1: tensor of type int16.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AscendRequantmd">AscendRequant</h2>

### Description 

Performs requantization.

### Parameters 

[Inputs]

Two inputs

x0: tensor of type int32.

req\_scale: tensor of type uint64.

[Attributes]

One attribute

Relu\_flag: bool

[Outputs]

One output

y: tensor of type int8.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AscendQuantmd">AscendQuant</h2>

### Description 

Performs quantization.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Attributes]

Four attributes

offset: float

scale: float

Sqrt\_mode: bool

Round\_mode: string

[Outputs]

One output

y: tensor of type int8.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AscendDequantS16md">AscendDequantS16</h2>

### Description 

Performs dequantization.

### Parameters 

[Inputs]

Two required inputs and one optional input

x0: tensor of type int32.

req\_scale: tensor of type uint64.

x1: tensor of type int16.

[Attributes]

One attribute

Relu\_flag: bool

[Outputs]

One output

y: tensor of type int16.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AscendDequantmd">AscendDequant</h2>

### Description 

Performs dequantization.

### Parameters 

[Inputs]

Two inputs

x0: tensor of type int32.

deq\_scale: tensor of type uint64 or float16.

[Attributes]

Sqrt\_mode: bool

Relu\_flag: bool

dtype: float

[Outputs]

One output

y: tensor of type float16 or float.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="AscendAntiQuantmd">AscendAntiQuant</h2>

### Description 

Performs dequantization.

### Parameters 

[Inputs]

One input

x: tensor of type int8.

[Attributes]

offset: float

scale: float

sqrt\_mode: bool

round\_mode: string

[Outputs]

One output

y: tensor of type float16 or float.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="Asinmd">Asin</h2>

### Description 

Computes trignometric inverse sine of the input element-wise.

### Parameters 

[Inputs]

One input

x1: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Asinhmd">Asinh</h2>

### Description 

Computes inverse hyperbolic sine of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Atanmd">Atan</h2>

### Description 

Computes the trignometric inverse tangent of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Atanhmd">Atanh</h2>

### Description 

Computes inverse hyperbolic tangent of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="AveragePoolmd">AveragePool</h2>

### Description 

Performs average pooling.

### Parameters 

[Inputs]

X: tensor of type float16 or float32, in NCHW format.

[Outputs]

Y: tensor of type float16 or float32, in NCHW format.

[Attributes]

auto\_pad: (optional)selected from NOTSET, SAME\_UPPER, SAME\_LOWER, and VALID.

count\_include\_pad: int, not supported currently.

kernel\_shape: (optional)

kernel\_shape\[0\]: int32, the kernel height. Must be in the range [1, 32768]. Defaults to 1.

kernel\_shape\[0\]: int32, the kernel width. Must be in the range [1, 32768]. Defaults to 1.

strides: (optional)

strides[0]: int32, the stride height. Defaults to 1.

strides[1]: int32, the stride width. Defaults to 1.

pads: (optional)

pads[0]: int32, top padding. Defaults to 0.

pads[1]: int32, bottom padding. Defaults to 0.

pads[2]: int32, left padding. Defaults to 0.

pads[3]: int32, right padding. Defaults to 0.

ceil_mode: (optional) int32, either 0 (floor mode) or 1 (ceil mode). Defaults to 0.

[Restrictions]

When strides[0] or strides[1] is greater than 63, computation is performed on AI CPU, which will compromise performance.

When the value of kernel\_shape\_H or kernel\_shape\_W is beyond the range [1, 255] or kernel\_shape\_H \* kernel\_shape\_W \> 256, computation is performed on AI CPU, which will compromise performance.

1 <= input\_w <= 4096;

When N of the input tensor is a prime number, N < 65535.

ceil\_mode is valid only when auto\_pad is set to NOTSET.

The operator does not support inputs of type float32 when the atc command-line option **--precision\_mode** is set to **must\_keep\_origin\_dtype**.

Beware that both the SAME_UPPER and SAME_LOWER values of auto_pad are functionally the same as the SAME argument of built-in TBE operators. The attribute configuration may lead to accuracy drop as the SAME argument is position-insensitive.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="BatchNormalizationmd">BatchNormalization</h2>

### Description 

Normalizes the inputs.

### Parameters 

[Inputs]

Five inputs

X: 4D tensor of type float16 or float32.

scale: tensor of type float32, specifying the scale factor.

B: tensor of type float32, specifying the offset.

mean: tensor of type float32, specifying the mean value.

var: tensor of type float32, specifying the variance value.

[Outputs]

Five outputs

Y: normalized tensor of type float16 or float32.

mean: mean value.

var: variance value.

saved_mean: saved mean value, used to accelerate gradient calculation during training.

saved_var: saved variance value, used to accelerate gradient calculation during training.

[Attributes]

epsilon: (optional) float32, added to var to avoid dividing by zero. Defaults to 0.0001.

momentum: float32, not supported currently.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="BatchMatMulmd">BatchMatMul</h2>

### Description 

Multiplies slices of two tensors in batches.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type float16, float, or int32.

x2: tensor of type float16, float, or int32.

[Attributes]

Two attributes

adj\_x1: bool

adj\_x2: bool

[Outputs]

One output

y: tensor of type float16, float, or int32.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="BatchMultiClassNMSmd">BatchMultiClassNMS</h2>

### Description 

Applies non-maximum suppression (NMS) on input boxes and input scores.

### Parameters 

[Inputs]

Two required inputs and two optional inputs

boxes: tensor of type float16

scores: tensor of type float16

clip\_window: tensor of type float16

num\_valid\_boxes: tensor of type int32

[Attributes]

Six attributes

score\_threshold: float

iou\_threshold: float

max\_size\_per\_class: int

max\_total\_size: int

change\_coordinate\_frame: bool

transpose\_box: bool

[Outputs]

Four outputs

nmsed\_boxes: tensor of type float16

nmsed\_scores: tensor of type float16

nmsed\_classes: tensor of type float16

nmsed\_num: tensor of type float16

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="BitShiftmd">BitShift</h2>

### Description

Performs element-wise shift.

### Parameters

[Inputs]

Two inputs

x: tensor, indicating the input to be shifted.

y: tensor, indicating the amounts of shift.

[Outputs]

z: shifted tensor.

[Attributes]

direction: (required) string, indicating the direction of moving bits. Either RIGHT or LEFT.

[Restrictions]

When direction is set to LEFT, the inputs must not be of type UINT16, UIN32, or UINT64.

### ONNX Opset Support

Opset v11/v12/v13

<h2 id="Castmd">Cast</h2>

### Description 

Casts a tensor to a new type.

### Parameters 

[Inputs]

One input

x: tensor

[Outputs]

y: tensor of the data type specified by the attribute. Must be one of the following types: bool, float16, float32, int8, int32, uint8.

[Attributes]

to: (required) int, the destination type.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Ceilmd">Ceil</h2>

### Description

Returns the ceiling of the input, element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Celumd">Celu</h2>

### Description

Continuously Differentiable Exponential Linear Units (CELUs): performs the linear unit element-wise on the input tensor X using formula:

max\(0,x\) + min\(0,alpha\*\(exp\(x/alpha\)-1\)\)

### Parameters 

[Inputs]

X: tensor of type float.

[Outputs]

Y: tensor of type float.

[Attributes]

alpha: float. Defaults to 1.0.

### ONNX Opset Support

Opset v12/v13

<h2 id="Concatmd">Concat</h2>

### Description

Concatenates multiple inputs.

### Parameters 

[Inputs]

inputs: tensors. Must be one of the following data types: float16, float32, int32, uint8, int16, int8, int64, qint8, quint8, qint32, uint16, uint32, uint64, qint16, quint16.

[Outputs]

concat\_result: tensor of the identical data type as inputs.

[Attributes]

axis: the axis along which to concatenate — may be negative to index from the end. Must be in the range [–r, r – 1], where, r = rank(inputs).

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Clipmd">Clip</h2>

### Description

Clips tensor values to a specified min and max.

### Parameters 

[Inputs]

Three inputs

X: tensor of type float16, float32, or int32.

min: must be a scalar.

max: must be a scalar.

[Outputs]

One output

Y: output tensor with clipped input elements. Has an identical shape and data type to those of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ConvTransposemd">ConvTranspose</h2>

### Description

Computes transposed convolution.

### Parameters 

[Inputs]

Three inputs

x: tensor of type float16 or float32.

w: tensor of type float16 or float32.

b: (optional) tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Attributes]

auto\_pad: string. Defaults to NOTSET, which means explicit padding is used.

dilations: ints. Dilation value along each spatial axis of the filter. Defaults to 1, meaning along each spatial axis.

group: int. Number of groups input channels and output channels are divided into. Defaults to 1.

kernel\_shape: ints. The shape of the convolution kernel. Defaults to w.

output\_padding: ints, specifying the value of padding. Defaults to an all-0 array.

output_shape: ints. The shape of the output can be explicitly set which will cause pads values to be auto generated.

pads: ints. Padding for the beginning and ending along each spatial axis. Defaults to an all-0 matrix.

strides: ints. Stride along each spatial axis. Defaults to an all-1 matrix.

[Restrictions]

Currently, only 2D transposed convolution is supported. 3D and higher are not supported.

dilations can only be 1.

Currently, the output_shape can be used to specify the output shape size. But the specified size must not be greater than the input size.

The operator does not support inputs of type float32 or float64 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

The auto_pad attribute cannot be SAME_UPPER or SAME_LOWER.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Cumsummd">Cumsum</h2>

### Description

Performs cumulative sum of the input elements along the given axis.

### Parameters 

[Inputs]

Two inputs

x: tensor of type float16, float32, or int32.

axis: scalar of type int32 or int64. Defaults to 0. Must be in the range [–rank(x), rank(x) – 1].

[Outputs]

One output

y: tensor. Has an identical data type to that of input x.

[Attributes]

exclusive: int. Whether to return exclusive sum in which the top element is not included. Defaults to 0.

reverse: int. Whether to perform the sums in reverse direction. Defaults to 0.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Convmd">Conv</h2>

### Description

Computes convolution.

### Parameters 

[Inputs]

X: 4D tensor

W: tensor for the weight

B: (optional) 1D tensor for the bias

[Outputs]

Y: tensor for the convolution output

[Attributes]

auto\_pad: (optional) either VALID or NOTSET

dilations: list of four integers, specifying the dilation rate. The value range for the H and W dimensions is [1, 255].

group: int32. The input and output channels are separated into groups, and the output group channels will be only connected to the input group channels. Both the input and output channels must be divisible by group. Must be 1.

pads: list of four integers, specifying the number of pixels to add to each side of the input. Must be in the range [0, 255].

strides: list of four integers, specifying the strides of the convolution along the H and W dimensions. The value range for the H and W dimensions is [1, 63]. By default, the N and C dimensions are set to 1.

[Restrictions]

For input X, the value range for the W dimension is [1, 4096].

For the weight tensor, the value range for the H and W dimensions is [1, 255].

When W and H of the output tensor are both 1, inputs X and W must have the same H and W dimensions.

The operator is not supported if the output Y meets: W = 1, H ! = 1

The operator does not support inputs of type float32 or float64 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Compressmd">Compress</h2>

### Description

Slices data based on the specified axis.

### Parameters 

[Inputs]

Two inputs:

input: tensor with one or more dimensions. The supported types are uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, string, and bool.

condition: 1-dimensional tensor, used to specify slices and elements to be selected. The supported type is bool.

[Outputs]

One output

output: tensor of the same type as the input

[Attributes]

(Optional) axis: int, axis for slicing. If no axis is specified, the input tensor is flattened before slicing. The value range is [-r, r-1]. r indicates the dimensions of the input tensor.

### ONNX Opset Support

Opset v9//v11/v12/v13

<h2 id="Constantmd">Constant</h2>

### Description

Creates a constant tensor.

### Parameters 

[Inputs]

None

[Outputs]

One output

Y: output tensor containing the same value of the provided tensor.

[Attributes]

value: the value for the elements of the output tensor.

[Restrictions]

sparse\_value: not supported

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ConstantOfShapemd">ConstantOfShape</h2>

### Description

Generates a tensor with given value and shape.

### Parameters 

[Inputs]

x: 1D tensor of type int64, the shape of the output tensor. All values must be greater than 0.

[Outputs]

y: output tensor of shape specified by the input. If value is specified, the value and data type of the output tensor is taken from value. If value is not specified, the value in the output defaults to 0, and the data type defaults to float32.

[Attributes]

value: the value and data type of the output elements.

[Restrictions]

x: 1 <= len(shape) <= 8

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Cosmd">Cos</h2>

### Description

Computes cos of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Coshmd">Cosh</h2>

### Description

Computes hyperbolic cosine of the input element-wise.

### Parameters 

[Inputs]

One input

x1: tensor of type float16, float, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to those of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="DeformableConv2Dmd">DeformableConv2D</h2>

### Description

Deformable convolution

### Parameters

[Inputs]

X: 4D tensor

filter: weight tensor

offsets: 4D tensor for the offset

bias: (optional) 1D tensor for the bias

[Outputs]

Y: deformed tensor

[Attributes]

auto\_pad: (optional) either VALID or NOTSET

dilations: list of four integers, specifying the dilation rate. The value range for the H and W dimensions is [1, 255].

group: int32. The input and output channels are separated into groups, and the output group channels will be only connected to the input group channels. Both the input and output channels must be divisible by group. Must be 1.

pads: list of four integers, specifying the number of pixels to add to each side of the input. Must be in the range [0, 255].

strides: list of four integers, specifying the strides of the convolution along the H and W dimensions. The value range for the H and W dimensions is [1, 63]. By default, the N and C dimensions are set to 1.

data_format: string, specifying the format of the input data. Defaults to NHWC.

deformable_groups: number of deformable group partitions. Defaults to 1

modulated: bool, specifying the DeformableConv2D version. Set to true to use v2; set to false to use v1. Currently, only true (v2) is supported.

[Restrictions]

For the input tensor X, expected range of the W dimension is [1, 4096/filter_width] and expected range of the H dimension is [1, 100000/filter_height].

For the weight tensor, expected range of both the W and H dimensions are [1, 63].

The operator does not support inputs of type float32 or float64 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="Detmd">Det</h2>

### Description

Calculates determinant of a square matrix or batches of square matrices.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="DepthToSpacemd">DepthToSpace</h2>

### Description

Rearranges (permutes) data from depth into blocks of spatial data.

### Parameters 

[Inputs]

One input

input: input tensor in format NCHW. Must be one of the following types: float16, float32, double, int32, int64.

[Outputs]

One output

output: tensor with shape [N, C/(blocksize * blocksize), H * blocksize, W * blocksize]

[Attributes]

blocksize: (required) int, blocks to be moved.

mode: string, either DCR (default) for depth-column-row order re-arrangement or CRD for column-row-depth order arrangement.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Divmd">Div</h2>

### Description

Performs element-wise division.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type float16, float32, double, int32, or int64.

x2: tensor of type float16, float32, double, int32, or int64.

[Outputs]

One output

y: tensor. Has an identical data type to that of the input.

[Restrictions]

The output has an identical data type to that of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Dropoutmd">Dropout</h2>

### Description

Copies or masks the input tensor.

### Parameters 

[Inputs]

One to three inputs

data: input tensor of type float16, float32, or double.

ratio: (optional) float16, float32, or double.

training\_mode: (optional) bool

[Outputs]

One to two outputs

output: tensor

mask: tensor

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Elumd">Elu</h2>

### Description

Computes the exponential linear function.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Attributes]

alpha: float, indicating the coefficient. Defaults to 1.0.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="EmbeddingBagmd">EmbeddingBag</h2>

### Description

Computes sums, means, or maxes of bags of embeddings.

### Parameters 

[Inputs]

Two required inputs and two optional inputs

weight: tensor of type float32.

indices: tensor of type int32.

offset: tensor of type int32.

per_sample_weights: tensor of type float32

[Attributes]

Four attributes

mode: string

scale_grad_by_fraq: bool

sparse: bool

include_last_offset: bool

[Outputs]

One output

y: tensor of type float32.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="Equalmd">Equal</h2>

### Description

Returns the truth value of (X1 == X2) element-wise.

### Parameters 

[Inputs]

Two inputs

X1: tensor

X2: tensor

[Outputs]

One output

y: tensor of type bool.

[Restrictions]

X1 and X2 have the same format and data type. The following data types are supported: bool, uint8, int8, int16, int32, int64, float16, float32, and double.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Erfmd">Erf</h2>

### Description

Computes the Gauss error function of x element-wise.

### Parameters

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and format to those of the input.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Expmd">Exp</h2>

### Description

Computes exponential of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Expandmd">Expand</h2>

### Description

Broadcasts the input tensor following the given shape and the broadcast rule.

### Parameters 

[Inputs]

Two inputs

input: tensor of type float16 or float32.

shape: tensor of type int64.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Restrictions]

The model's input shape need to be changed from placeholders to constants. You can use ONNX Simplifier to simplify your model.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="EyeLikemd">EyeLike</h2>

### Description

Generate a 2D tensor (matrix) with ones on the diagonal and zeros everywhere else.

### Parameters

[Inputs]

One input

x: 2D tensor, to be copied.

[Outputs]

One output

y: tensor of the identical shape as input x.

[Attributes]

dtype: int, specifying the data type of the output.

k: int, specifying the index of the diagonal to be populated with ones. Defaults to 0. If y is output, y[i, i+k] = 1.

[Restrictions]

k must be 0.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Flattenmd">Flatten</h2>

### Description

Flattens the input.

### Parameters 

[Inputs]

input: ND tensor. Must be one of the following data types: int8, uint8, int16, uint16, int32, uint32, int64, uint64, float16, float32.

[Outputs]

2D tensor with the content of the input tensor.

[Attributes]

axis: int. Must be positive.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Floormd">Floor</h2>

### Description

Returns element-wise largest integer not greater than x.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Gathermd">Gather</h2>

### Description

Gathers slices from the input according to indices.

### Parameters

[Inputs]

Two inputs

x1: tensor of type float16, float32, int32, int64, int8, int16, uint8, uint16, uint32, uint64, or bool.

indices: tensor of type int32 or int64.

[Outputs]

One output

y: tensor. Has an identical data type to that of input x1.

[Attributes]

axis: int, the axis in x1 to gather indices from. Must be in the range [–r, r – 1], where r indicates the rank of the input x1.

[Restrictions]

indices must not be negative.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="GatherNDmd">GatherND</h2>

### Description

Gathers slices of data into an output tensor.

### Parameters 

[Inputs]

Two inputs

data: input tensor of rank r >= 1. Must be one of the following types: float16, float32, double, int32, int64.

indices: tensor of type int64, of rank q >= 1.

[Outputs]

One output

output: tensor of q + r - indices_shape[-1] - 1

[Attributes]

batch_dims: int, the number of batch dimensions. Defaults to 0.

[Restrictions]

The operator does not support inputs of type double when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

Opset v11/v12/v13

<h2 id="GatherElementsmd">GatherElements</h2>

### Description

Produces an output by indexing into the input tensor at index positions.

### Parameters 

[Inputs]

Two inputs

input: input tensor of rank > 1. Must be one of the following types: float16, float32, double, int32, int64.

indices: tensor of type int32 or int64.

[Outputs]

One output

output: tensor with the same shape as indices.

[Attributes]

axis: int, the axis to gather on. Defaults to 0.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Gemmmd">Gemm</h2>

### Description

General matrix multiplication

### Parameters 

[Inputs]

A: 2D tensor of type float16 or float32.

B: 2D tensor of type float16 or float32.

C: (optional) bias, not supported currently.

[Outputs]

Y: 2D tensor of type float16 or float32.

[Attributes]

transA: bool, indicating whether A needs to be transposed.

transB: bool, indicating whether B needs to be transposed.

alpha: float, not supported currently.

beta: float, not supported currently.

[Restrictions]

Opset V8, V9, and V10 versions do not support inputs of type float32 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="GlobalAveragePoolmd">GlobalAveragePool</h2>

### Description

Performs global average pooling.

### Parameters 

[Inputs]

X: tensor of type float16 or float32, in NCHW format.

[Outputs]

Y: pooled tensor in NCHW format. Has the same data type as X.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="GlobalLpPoolmd">GlobalLpPool</h2>

### Description

Performs global norm pooling.

### Parameters 

[Inputs]

Two inputs

input: tensor of type float16 or float32.

(Optional) p: int32. Defaults to 2.

[Outputs]

One output

y: tensor of the same data type as input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="GlobalMaxPoolmd">GlobalMaxPool</h2>

### Description

Performs global max pooling.

### Parameters 

[Inputs]

One input

x: output tensor of the upstream node. Must be of type float16, float32, or double.

[Outputs]

One output

output: pooled tensor

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Greatermd">Greater</h2>

### Description

Returns the truth value of (x1 >= x2) element-wise.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type float16, float32, int32, int8, or uint8.

x2: tensor of type float16, float32, int32, int8, or uint8.

[Outputs]

One output

y: tensor of type bool.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="GreaterOrEqualmd">GreaterOrEqual</h2>

### Description

Returns the truth value of (x1 >= x2) element-wise.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type float16, float32, int32, int8, or uint8.

x2: tensor of type float16, float32, int32, int8, or uint8.

[Outputs]

One output

y: tensor of type bool.

### ONNX Opset Support

Opset v8/v12

<h2 id="HardSigmoidmd">HardSigmoid</h2>

### Description

Takes one input data (tensor) and produces one output data (tensor) where the HardSigmoid function, y = max(0, min(1, alpha * x + beta)), is applied to the tensor element-wise.

### Parameters 

[Inputs]

One input

X: tensor of type float16, float, or double.

[Outputs]

One output

Y: tensor of type float16, float, or double.

[Attributes]

alpha: float. Defaults to 0.2.

beta: float. Defaults to 0.2.

### ONNX Opset Support

Opset v1/v6/v8/v9/v10/v11/v12/v13

<h2 id="hardmaxmd">hardmax</h2>

### Description

Computes the hardmax values for the given input: Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32, of rank = 2.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Attributes]

axis: int. The dimension Hardmax will be performed on. Defaults to –1.

[Restrictions]

In the atc command line, the --precision_mode option must be set to allow_fp32_to_fp16.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="HardSwishmd">HardSwish</h2>

### Description

Applies the HardSwish function. y=x * max(0, min(1, alpha * x + beta )), where alpha is 1/6 and beat is 0.5.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type float16 or float32.

### ONNX Opset Support

Opset v14

<h2 id="Identitymd">Identity</h2>

### Description

Identity operator

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Ifmd">If</h2>

### Description

If conditional

### Parameters 

[Inputs]

One input

cond: condition for the if operator.

Two attributes

else_branch: branch tensor to run if condition is false.

then_branch: branch tensor to run if condition is true.

[Outputs]

One or more outputs

y: tensor or list of tensors

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="InstanceNormalizationmd">InstanceNormalization</h2>

### Description

Computes a tensor by using the formula: y = scale * (x – mean) / sqrt(variance + epsilon) + B, where mean and variance are computed per instance per channel.

### Parameters

[Inputs]

Three inputs

x: tensor of type float16 or float.

scale: 1D tensor of the same size C of input x. Has an identical data type to that of input x.

B: 1D tensor of the same size C of input x. Has an identical data type to that of input x.

[Outputs]

One output

y: tensor of the identical data type and shape as input x.

[Attributes]

epsilon: float. The epsilon value to use to avoid division by zero. Defaults to 1e – 05.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Lessmd">Less</h2>

### Description

Returns the truth value of (x1 < x2) element-wise.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type float16, float32, int32, int8, or uint8.

x2: tensor of type float16, float32, int32, int8, or uint8.

[Outputs]

One output

y: tensor of type bool.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="LeakyRelumd">LeakyRelu</h2>

### Description

Computes the Leaky ReLU activation function.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and shape to those of the input.

[Attributes]

alpha: float, the leakage coefficient. Defaults to 0.01.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="LessOrEqualmd">LessOrEqual</h2>

### Description

Returns the truth value of (x <= y) element-wise.

### Parameters 

[Inputs]

Two inputs

x: tensor of type float16 or float32.

y: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type bool, with the same shape as the input x.

### ONNX Opset Support

Opset v12/v13

<h2 id="Logmd">Log</h2>

### Description

Computes natural logarithm of x element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type to that of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="LogSoftMaxmd">LogSoftMax</h2>

### Description

Computes log softmax activations.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

[Attributes]

axis: int. Must be in the range [–r, r – 1], where r indicates the rank of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="LpNormalizationmd">LpNormalization</h2>

### Description

Given a matrix, applies Lp-normalization along the provided axis.

### Parameters 

[Inputs]

One input

input: tensor of type float16 or float.

[Outputs]

One output

output: tensor of type float16 or float.

[Attributes]

axis: int. Defaults to –1.

p: int. Defaults to 2.

[Restrictions]

Beware that both the SAME_UPPER and SAME_LOWER values of auto_pad are functionally the same as the SAME argument of built-in TBE operators. The attribute configuration may lead to accuracy drop as the SAME argument is position-insensitive.

### ONNX Opset Support

Opset v1/v8/v9/v10/v11/v12/v13

<h2 id="LpPoolmd">LpPool</h2>

### Description

Performs Lp norm pooling.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type float16 or float32.

[Attributes]

auto\_pad: string. The value can be NOTSET (default), SAME_UPPER, or VALID.

(Required) kernel\_shape: int list, size of the kernel on each axis.

p: int, norm. Defaults to 2.

pads: int list.

strides: int list.

### ONNX Opset Support

Opset v11/v12/v13

<h2 id="LRNmd">LRN</h2>

### Description

Performs local response normalization.

### Parameters

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and format to those of input x.

[Attributes]

alpha: float, a scale factor.

beta: float, an exponent.

bias: float.

size: int, the number of channels to sum over. Must be odd.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="LSTMmd">LSTM</h2>

### Description

Computes a one-layer LSTM. This operator is usually supported via some custom implementation such as CuDNN.

### Parameters 

[3–8 Inputs]

X: tensor of type float16, float, or double.

W: tensor of type float16, float, or double.

R: tensor of type float16, float, or double.

B: tensor of type float16, float, or double.

sequence_lens: tensor of type int32.

initial_h:, tensor of type float 16, float, or double.

initial_c:, tensor of type float 16, float, or double.

p: tensor of type float16, float, or double.

[0–3 Outputs]

Y: tensor of type float16, float, or double.

Y_h:, tensor of type float 16, float, or double.

Y_c:, tensor of type float 16, float, or double.

[Attributes]

activation_alpha: list of floats

activation_beta: list of floats

activations: list of strings.

clip: float

direction: string. Defaults to forward.

hidden_size: int

input_forget: int. Defaults to 0.

layout: int. Defaults to 0.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="MatMulmd">MatMul</h2>

### Description

Multiplies two matrices.

### Parameters 

[Inputs]

Two inputs

x1: 2D tensor of type float16.

x2: 2D tensor of type float16.

[Outputs]

One output

y: 2D tensor of type float16.

[Restrictions]

Only 1D to 6D inputs are supported.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Maxmd">Max</h2>

### Description

Computes element-wise max of each of the input tensors.

### Parameters 

[Inputs]

One or more inputs (1–∞)

data_0: list of tensors. Must be one of the following types: float16, float32, int8, int16, int32.

[Outputs]

One output

max: tensor with the same type and shape as the input x (broadcast shape)

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="MaxPoolmd">MaxPool</h2>

### Description

Performs max pooling.

### Parameters 

[Inputs]

X: tensor of type float16 or float32, in NCHW format.

[Outputs]

Y: tensor of type float16 or float32, in NCHW format.

[Attributes]

auto_pad: (optional) selected from SAME_UPPER, SAME_LOWER, VALID, and NOTSET.

storage_order: not supported currently.

kernel_shape: (optional)

-   kernel\_shape\[0\]: int32, the kernel height. Must be in the range [1, 32768]. Defaults to 1.
-   kernel\_shape\[0\]: int32, the kernel width. Must be in the range [1, 32768]. Defaults to 1.

strides: (optional)

-   strides[0]: int32, the stride height. Defaults to 1.
-   strides[1]: int32, the stride width. Defaults to 1.

pads: (optional)

-   pads[0]: int32, top padding. Defaults to 0.
-   pads[1]: int32, bottom padding. Defaults to 0.
-   pads[2]: int32, left padding. Defaults to 0.
-   pads[3]: int32, right padding. Defaults to 0.

ceil_mode: (optional) int32, either 0 (floor mode) or 1 (ceil mode). Defaults to 0.

[Restrictions]

When strides[0] or strides[1] is greater than 63, computation is performed on AI CPU, which will compromise performance.

When the value of kernel\_shape\_H or kernel\_shape\_W is beyond the range [1, 255] or kernel\_shape\_H \* kernel\_shape\_W \> 256, computation is performed on AI CPU, which will compromise performance.

1 <= input\_w <= 4096

When N of the input tensor is a prime number, N < 65535.

dilations is not supported for a 2D tensor.

If auto_pad is VALID, ceil_mode must be 0.

The operator does not support inputs of type float32 when the atc command-line option --precision\_mode is set to must\_keep\_origin\_dtype.

pads and auto_pad are mutually exclusive.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="MaxRoiPoolmd">MaxRoiPool</h2>

### Description

Consumes an input tensor X and region of interests (RoIs) to apply max pooling across each RoI, to produce output 4-D tensor shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).

### Parameters 

[Inputs]

X: tensor of type float16 or float.

rois: tensor of type float16 or float.

[Outputs]

Y: tensor of type float16, float, or double.

[Attributes]

pooled_shape: list of ints

spatial_scale: float. Defaults to 1.0.

[Restrictions]

The operator does not support inputs of type float32 when the atc command-line option --precision\_mode is set to must\_keep\_origin\_dtype.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/13

<h2 id="MaxUnpoolmd">MaxUnpool</h2>

### Description

Indicates the reverse of the MaxPool operation.

### Parameters 

[Inputs]

X: tensor of type float16 or float32.

I: tensor of type int64.

(Optional) output_shape: output shape of type int64.

[Outputs]

Y: tensor of the same data type as the input.

[Attributes]

(Mandatory) kernel_shape: int list, kernel size on each axis.

pads: int list, pad on each axis.

strides: int list, stride on each axis.

### ONNX Opset Support

Opset v9/v11/v12/v13

<h2 id="Meanmd">Mean</h2>

### Description

Computes element-wise mean of each of the input tensors (with NumPy-style broadcasting support). All inputs and outputs must have the same data type. This operator supports multi-directional (NumPy-style) broadcasting.

### Parameters 

[Inputs] One or more inputs (1–∞)

data_0: tensor of type float16, float, double, or bfloat16.

[Outputs]

mean: tensor of type float16, float, double, or bfloat16.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="MeanVarianceNormalizationmd">MeanVarianceNormalization</h2>

### Description

Performs mean variance normalization on the input tensor X using formula: (X – EX)/sqrt(E(X – EX)^2)

### Parameters 

[Inputs]

X: tensor of type float16, float, or bfloat16.

[Outputs]

Y: tensor of type float16, float, or bfloat16.

[Attributes]

axes: list of ints. Defaults to ['0', '2', '3'].

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Minmd">Min</h2>

### Description

Returns the minimum of the input tensors.

### Parameters

[Inputs]

One input

x: list of tensors of type float16 or float32

[Outputs]

One output

y: output tensor

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Modmd">Mod</h2>

### Description

Performs element-wise binary modulus (with NumPy-style broadcasting support). The sign of the remainder is the same as that of the divisor.

### Parameters

[Inputs]

A: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, double, bfloat16.

B: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, double, bfloat16.

[Outputs]

C: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, double, bfloat16.

[Attributes]

fmod: int. Defaults to 0.

[Restrictions]

fmod must not be 0 if the inputs are of type float.

### ONNX Opset Support

Opset v10/v11/v12/v13

<h2 id="Mulmd">Mul</h2>

### Description 

Performs dot product of two matrices.

### Parameters 

[Inputs]

A: tensor of type float16, float32, uint8, int8, int16, or int32.

B: tensor of type float16, float32, uint8, int8, int16, or int32.

[Outputs]

C: tensor. Has an identical data type to that of the input tensor.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Multinomialmd">Multinomial</h2>

### Description 

Generates a tensor of samples from a multinomial distribution according to the probabilities of each of the possible outcomes.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32, with shape [batch_size, class_size].

[Outputs]

One output

y: tensor of type int32 or int64, with shape [batch_size, sample_size].

[Attributes]

dtype: int. The output dtype. Defaults to 6 (int32).

sample_size: Number of times to sample. Defaults to 1.

seed: float. Seed to the random generator.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Negmd">Neg</h2>

### Description 

Computes numerical negative value element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or int32.

[Outputs]

One output

y: tensor. Has an identical data type to that of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="NonMaxSuppressionmd">NonMaxSuppression</h2>

### Description 

Filters out boxes that have high intersection-over-union (IOU) overlap with previously selected boxes. Bounding boxes with score less than score_threshold are removed. Bounding box format is indicated by the center_point_box attribute. Note that this algorithm is agnostic to where the origin is in the coordinate system and more generally is invariant to orthogonal transformations and translations of the coordinate system; thus translating or reflections of the coordinate system result in the same boxes being selected by the algorithm. The selected_indices output is a set of integers indexing into the input collection of bounding boxes representing the selected boxes. The bounding box coordinates corresponding to the selected indices can then be obtained using the Gather or GatherND operation.

### Parameters 

[2–5 Inputs]

boxes: tensor of type float

scores: tensor of type float

max_output_boxes_per_class: (optional) tensor of type int64

iou_threshold: (optional) tensor of type float

score_threshold: (optional) tensor of type float

[Outputs]

selected_indices: tensor of type int64

[Attributes]

center_point_box: int. Defaults to 0.

### ONNX Opset Support

Opset v10/v11/v12/v13

<h2 id="NonZeromd">NonZero</h2>

### Description 

Returns the indices of the elements that are non-zero (in row-major order).

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, int32, int8, or uint8.

[Outputs]

One output

y: tensor of type int64.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Notmd">Not</h2>

### Description 

Returns the negation of the input tensor element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type bool.

[Outputs]

One output

y: tensor of type bool.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="OneHotmd">OneHot</h2>

### Description 

Produces a one-hot tensor based on inputs.

### Parameters

[Inputs]

Three inputs

indices: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, double.

depth: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, double.

values: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float, double.

[Attributes]

One attribute

axis: (optional) axis along which one-hot representation is added.

[Outputs]

One output

y: tensor of the identical data type as the values input.

[Restrictions]

axis must not be less than –1.

### ONNX Opset Support

Opset v9/v10/v11/v12/v13

<h2 id="Ormd">Or</h2>

### Description 

Returns the tensor resulted from performing the OR logical operation element-wise on the input tensors.

### Parameters

[Inputs]

Two inputs

X1: tensor of type bool.

X2: tensor of type bool.

[Outputs]

One output

y: tensor of type bool.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="RandomNormalLikemd">RandomNormalLike</h2>

### Description

Generates a tensor with random values drawn from a normal distribution. The shape of the output tensor is copied from the shape of the input tensor.

### Parameters

[Inputs]

One input

x: tensor of type float16 or float.

[Outputs]

One output

y: tensor of the identical data type and shape as input x.

[Attributes]

dtype: int, specifying the data type of the output tensor.

mean: float. The mean of the normal distribution. Defaults to 0.0.

scale: float. The standard deviation of the normal distribution. Defaults to 1.0.

seed: float. Seed to the random generator.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="RandomUniformLikemd">RandomUniformLike</h2>

### Description

Generates a tensor with random values drawn from a uniform distribution. The shape of the output tensor is copied from the shape of the input tensor.

### Parameters

[Inputs]

One input

x: tensor of type float16 or float.

[Outputs]

One output

y: tensor of the identical data type and shape as input x.

[Attributes]

dtype: int, specifying the data type of the output tensor.

high: float. Upper boundary of the uniform distribution. Defaults to 1.0.

low: float. Lower boundary of the uniform distribution. Defaults to 0.0.

seed: float. Seed to the random generator.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="RandomUniformmd">RandomUniform</h2>

### Description 

Generates a tensor with random values drawn from a uniform distribution.

### Parameters 

[Attributes]

Five attributes

dtype: int. Specifies the output data type.

high: float. Specifies the upper boundary.

low: float. Specifies the lower boundary.

seed: (optional) seed to the random generator.

shape: output shape.

[Outputs]

One output

y: tensor of the data type specified by the dtype attribute.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Rangemd">Range</h2>

### Description 

Generate a tensor containing a sequence of numbers.

### Parameters 

[Inputs]

Three inputs

start: scalar of type float16 or float32.

limit: scalar of type float16 or float32.

delta: scalar of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type to that of input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Reciprocalmd">Reciprocal</h2>

### Description 

Computes the reciprocal of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceL1md">ReduceL1</h2>

### Description 

Computes the L1 norm of the input tensor's elements along the provided axes. The resulted tensor has the same rank as the input if keepdim is set to 1. If keepdim is set to 0, then the result tensor has the reduced dimension pruned. The above behavior is similar to NumPy, with the exception that NumPy defaults keepdim to False instead of True.

### Parameters 

[Inputs]

data: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Outputs]

reduced: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Attributes]

axes: list of ints.

keepdims: int. Defaults to 1.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceL2md">ReduceL2</h2>

### Description

Computes the L2 norm of the input tensor's elements along the provided axes. The resulted tensor has the same rank as the input if keepdim is set to 1. If keepdim is set to 0, then the result tensor has the reduced dimension pruned. The above behavior is similar to NumPy, with the exception that NumPy defaults keepdim to False instead of True.

### Parameters 

[Inputs]

data: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Outputs]

reduced: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Attributes]

axes: list of ints.

keepdims: int. Defaults to 1.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceLogSummd">ReduceLogSum</h2>

### Description

Computes the sum of elements across dimensions of a tensor in log representations.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type float16 or float32.

[Attributes]

axes: int list. Must be in the range [–r, r – 1], where r indicates the dimension count of the input x.

keepdims: int. Defaults to 1, meaning that the reduced dimensions with length 1 are retained.

### ONNX Opset Support

Opset v11/v13

<h2 id="ReduceLogSumExpmd">ReduceLogSumExp</h2>

### Description

Reduces a dimension of a tensor by calculating exponential for all elements in the dimension and calculates logarithm of the sum.

### Parameters 

[Inputs]

One input

data: tensor of type float16 or float32.

[Outputs]

One output

reduced: tensor of type float16 or float32.

[Attributes]

axes: tensor of type int32 or int64. Must be in the range [–r, r – 1], where r indicates the dimension count of the input x.

keepdims: int, indicating whether to reduce the dimensions. The default value is 1, indicating that the dimensions are reduced.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceMinmd">ReduceMin</h2>

### Description

Computes the minimum of elements across dimensions of a tensor.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of type float16 or float32.

[Attributes]

axes: int list. Must be in the range [–r, r – 1], where r indicates the dimension count of the input x.

keepdims: int. Defaults to 1, meaning that the reduced dimensions with length 1 are retained.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceMeanmd">ReduceMean</h2>

### Description

Computes the mean of elements across dimensions of a tensor.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and format to those of input x.

[Attributes]

axes: 1D list of ints, the dimensions to reduce. Must be in the range [–r, r – 1], where r indicates the rank of the input.

keepdims: int. Defaults to 1, meaning that the reduced dimensions with length 1 are retained.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceProdmd">ReduceProd</h2>

### Description

Computes the product of the input tensor's elements along the provided axes. The resulted tensor has the same rank as the input if keepdim is set to 1. If keepdim is set to 0, then the result tensor has the reduced dimension pruned.

### Parameters 

[Inputs]

data: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Outputs]

reduced: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Attributes]

axes: list of ints.

keepdims: int. Defaults to 1.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceSumSquaremd">ReduceSumSquare</h2>

### Description

Computes the sum square of the input tensor's elements along the provided axes. The resulted tensor has the same rank as the input if keepdim is set to 1. If keepdim is set to 0, then the result tensor has the reduced dimension pruned. The above behavior is similar to NumPy, with the exception that NumPy defaults keepdim to False instead of True.

### Parameters 

[Inputs]

data: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Outputs]

reduced: tensor. Must be one of the following types: uint32, uint64, int32, int64, float16, float, double, bfloat16.

[Attributes]

axes: list of ints.

keepdims: int. Defaults to 1.

### ONNX Opset Support

Opset v1/v8/v9/v10/v11/v12/v13

<h2 id="Resizemd">Resize</h2>

### Description

Resizes the input tensor.

### Parameters 

[Inputs]

Four inputs

x: tensor of type float16 or float32.

roi: 1D tensor of type float16 or float32, with shape [start1, ..., startN, end1, ..., endN]. The tensor is normalized by the input image.

scales: array. Has the same rank as that of the input x.

sizes: size of the output tensor.

[Outputs]

One output

y: resized tensor

[Attributes]

coordinate_transformation_mode: string. Defaults to half_pixel. Describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor.

cubic_coeff_a: float. The coefficient used in cubic interpolation. Defaults to –0.75.

exclude_outside: int. The weight outside the tensor. Defaults to 0.

mode: string. Interpolation mode selected from nearest (default), linear, and cubic.

nearest_mode: string. Nearest operator mode. Defaults to round_prefer_floor.

[Restrictions]

Currently, only the nearest and linear interpolation modes are supported to process images. In addition, the model's two inputs (scales and sizes) need to be changed from placeholders to constants. You can use ONNX Simplifier to simplify your model.

### ONNX Opset Support

Opset v10/v11/v12

<h2 id="Relumd">Relu</h2>

### Description

Applies the rectified linear unit activation function.

### Parameters 

[Inputs]

X: input tensor of type float32, int32, uint8, int16, int8, uint16, float16, or qint8

[Outputs]

Y: tensor. Has an identical data type to that of X.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceSummd">ReduceSum</h2>

### Description

Computes the sum of the input tensor's element along the provided axes.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type and format to those of input x.

[Attributes]

axes: 1D list of ints, the dimensions to reduce. Must be in the range [–r, r – 1], where r indicates the rank of the input.

keepdims: int. Defaults to 1, meaning that the reduced dimensions with length 1 are retained.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReduceMaxmd">ReduceMax</h2>

### Description

Computes the maximum of elements across dimensions of a tensor.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or int32.

[Outputs]

One output

y: tensor of type float16, float32, or int32.

[Attributes]

axes: list of ints. Must be in the range [–r, r – 1], where r indicates the rank of the input.

keepdims: int. Defaults to 1, meaning that the reduced dimensions with length 1 are retained.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Reshapemd">Reshape</h2>

### Description

Reshapes the input.

### Parameters 

[Inputs]

Two inputs

data: tensor.

shape: tensor of type int64, for the shape of the output tensor.

[Outputs]

reshaped: tensor

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ReverseSequencemd">ReverseSequence</h2>

### Description

Reverses batch of sequences having different lengths.

### Parameters 

[Inputs]

Two inputs

x: tensor of type float16 or float32, of rank >= 2.

sequence_lens: tensor of type int64. Lengths of the sequences in a batch.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Attributes]

batch_axis: int. Specifies the batch axis. Defaults to 1.

time_axis: int. Specifies the time axis. Defaults to 1.

### ONNX Opset Support

Opset v10/v11/v12/v13

<h2 id="RoiExtractormd">RoiExtractor</h2>

### Description

Obtains the ROI feature matrix from the feature mapping list.

### Parameters 

[Inputs]

Two inputs

features: tensor of type float32 or float16.

rois: tensor of type float32 or float16.

[Attributes]

Eight attributes

finest_scale: int 

roi_scale_factor: float

spatial_scale: array of floats

pooled_height: int

pooled_width: int 

sample_num: int

pool_mode: string

aligned: bool

[Outputs]

One output

y: tensor of type float32 or float16.

### ONNX Opset Support

No ONNX support for this custom operator.

<h2 id="RoiAlignmd">RoiAlign</h2>

### Description

Performs ROI align operation.

### Parameters 

[Inputs]

Three inputs

x: 4D tensor of type float16 or float32.

rois: float16 or float32 with shape (num_rois, 4).

batch_indices: int64 with shape (num_rois,).

[Outputs]

One output

y: tensor of the identical type as input x. Has shape (num_rois, C, output_height, output_width).

[Attributes]

mode: string. The pooling method. Defaults to avg.

output_height: int. Pooled output y's height. Defaults to 1.

output_width: int. Pooled output y's width. Defaults to 1.

sampling_ratio: int. Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. Defaults to 0.

spatial_scale: float. Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling. Defaults to 1.0.

[Restrictions]

batch_indices must be of type int32 instead of int64.

The operator does not support inputs of type float32 or float64 when the atc command-line option --precision_mode is set to must_keep_origin_dtype.

### ONNX Opset Support

Opset v10/v11/v12/v13

<h2 id="Roundmd">Round</h2>

### Description

Rounds the values of a tensor to the nearest integer, element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="PRelumd">PRelu</h2>

### Description

Computes Parametric Rectified Linear Unit.

### Parameters 

[Inputs]

Two inputs

x: tensor of type float16 or float32.

slope: tensor of the same data type as input x.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Restrictions]

slope must be 1D. When input x is 1D, the dimension value of slope must be 1. When input x is not 1D, the dimension value of slope can be 1 or shape[1] of input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Scattermd">Scatter</h2>

### Description

Returns the result by updating the values of the input data to values specified by updates at specific index positions specified by indices.

### Parameters

[Inputs]

Three inputs

data: tensor of type float16, float, or int32.

indices: tensor of type int32 or int64.

updates: tensor of the identical data type as data.

[Outputs]

One output

y: tensor of the identical data type and shape as input x.

[Attributes]

axis: int, specifying which axis to scatter on. Defaults to 0.

### ONNX Opset Support

Opset v9/v10

<h2 id="ScatterElementsmd">ScatterElements</h2>

### Description

Returns the result by updating the values of the input data to values specified by updates at specific index positions specified by indices.

### Parameters

[Inputs]

One input

data: tensor of type float16, float, or int32.

indices: tensor of type int32 or int64.

updates: tensor of the identical data type as data.

[Outputs]

One output

y: tensor of the identical data type and shape as input x.

[Attributes]

axis: int, specifying which axis to scatter on. Defaults to 0.

### ONNX Opset Support

Opset v11/v12/v13

<h2 id="ScatterNDmd">ScatterND</h2>

### Description

Creates a copy of the input data, and then updates its values to those specified by updates at specific index positions specified by indices.

### Parameters 

[Inputs]

Three inputs

data: tensor of type float16 or float32, of rank >= 1.

indices: tensor of type int64, of rank >= 1.

updates: tensor of type float16 or float32, of rank = q + r – indices_shape[–1] – 1.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

### ONNX Opset Support

Opset v11

<h2 id="Shrinkmd">Shrink</h2>

### Description

Takes one input tensor and outputs one tensor. The formula of this operator is: If x < – lambd, y = x + bias; If x > lambd, y = x – bias; otherwise, y = 0.

### Parameters

[Inputs]

One input

data: tensor of type float16 or float.

[Outputs]

One output

y: tensor of the identical data type and shape as input x.

[Attributes]

bias: float. Defaults to 0.0.

lambda: float. Defaults to 0.5.

### ONNX Opset Support

Opset v9/v10/v11/ v12/v13

<h2 id="Selumd">Selu</h2>

### Description

Produces a tensor where the scaled exponential linear unit function: y = gamma * (alpha * e^x – alpha) for x <= 0, y = gamma * x for x > 0, is applied to the input tensor element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

Two attributes

alpha: coefficient of SELU

gamma: coefficient of SELU

[Outputs]

One output

y: tensor of the identical data type as the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Shapemd">Shape</h2>

### Description

Returns a tensor containing the shape of the input tensor.

### Parameters

[Inputs]

One input

x: tensor

[Outputs]

y: int64 tensor with the shape of the input tensor.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Sigmoidmd">Sigmoid</h2>

### Description

Computes sigmoid of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type to that of input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Slicemd">Slice</h2>

### Description

Extracts a slice from a tensor.

### Parameters 

[Inputs]

Five inputs

x: tensor of type float16, float32, int32, uint8, bool, or int8.

starts: 1D tensor of type int32 or int64, specifying the start index.

ends: 1D tensor of type int32 or int64, specifying the end index.

axes: (optional) 1D tensor of type int32 or int64. The axis to extract a slice from. Must be in the range [–r, r – 1], where r indicates the rank of the input x.

steps: (optional) 1D tensor of type int32 or int64, specifying the slice step. The slice step of the last axis must be 1.

[Outputs]

y: tensor. Has an identical data type to that of the input.

[Restrictions]

x: The dimension of the input tensor cannot be 1.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Softmaxmd">Softmax</h2>

### Description

Computes softmax activations.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to those of input x.

[Attributes]

axis: (optional) int, the dimension softmax would be performed on. Defaults to –1. Must be in the range [–len(x.shape), len(x.shape) – 1].

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Softsignmd">Softsign</h2>

### Description

Computes softsign: (x/(1+|x|))

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Softplusmd">Softplus</h2>

### Description

Computes softplus.

### Parameters 

[Inputs]

One input

X: 1D input tensor

[Outputs]

One output

Y: 1D tensor

[Restrictions]

Only the float16 and float32 data types are supported.

The output has an identical data type to that of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="SpaceToDepthmd">SpaceToDepth</h2>

### Description

Rearranges blocks of spatial data into depth. More specifically, this operator outputs a copy of the input tensor where values from the height and width dimensions are moved to the depth dimension.

### Parameters 

[Inputs]

input: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, bfloat16, float16, float, double, string, bool, complex64, complex128.

[Outputs]

output: tensor. Must be one of the following data types: uint8, uint16, uint32, uint64, int8, int16, int32, int64, bfloat16, float16, float, double, string, bool, complex64, complex128.

[Attributes]

blocksize: int

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Splitmd">Split</h2>

### Description

Splits the input tensor into a list of sub-tensors.

### Parameters 

[Inputs]

One input

x: tensor. Must be one of the following types: float16, float32, int8, int16, int32, int64, uint8, uint16, uint32, uint64.

[Outputs]

One output

y: list of tensors. Has an identical data type to that of input x.

[Attributes]

split: list of type int8, int16, int32, or int64, for the length of each output along axis.

axis: int8, int16, int32, or int64, for the axis along which to split.

[Restrictions]

Each element of split must be greater than or equal to 1.

The sum of all split elements must be equal to axis.

axis ∈ [–len(x.shape), len(x.shape) – 1]

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Sqrtmd">Sqrt</h2>

### Description

Computes element-wise square root of the input tensor.

### Parameters 

[Inputs]

One input

x: tensor

[Outputs]

One output

y: tensor

[Restrictions]

The output has the identical shape and dtype as the input. The supported data types are float16 and float32.

If x is less than 0, NaN is returned.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Squeezemd">Squeeze</h2>

### Description

Removes dimensions of size 1 from the shape of a tensor.

### Parameters 

[Inputs]

One input

x: tensor. Must be one of the following data types: float16, float32, double, uint8, uint16, uint32, uint64, int8, int16, int32, int64, bool.

[Outputs]

y: tensor. Has an identical data type to that of the input.

[Attributes]

axes: 1D list of int32s or int64s, indicating the dimensions to squeeze. Negative value means counting dimensions from the back. Accepted range is [–r, r – 1] where r = rank(x).

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Submd">Sub</h2>

### Description

Performs element-wise subtraction.

### Parameters 

[Inputs]

Two inputs

x1: tensor

x2: tensor

[Outputs]

One output

y: tensor. Has an identical data type to that of the input.

[Restrictions]

The output has the identical shape and dtype as the input. The supported data types are int32, float16, and float32.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Signmd">Sign</h2>

### Description

Computes the symbol of the input tensor element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Sinmd">Sin</h2>

### Description

Computes sine of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Sinhmd">Sinh</h2>

### Description

Computes hyperbolic sine of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16, float32, or double.

[Outputs]

One output

y: tensor. Has an identical data type and shape to the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Sizemd">Size</h2>

### Description

Outputs the number of elements in the input tensor.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: scalar of type int64

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Summd">Sum</h2>

### Description

Computes element-wise sum of each of the input tensors.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Tanhmd">Tanh</h2>

### Description

Computes hyperbolic tangent of the input element-wise.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor. Has an identical data type to that of the input.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="TfIdfVectorizermd">TfIdfVectorizer</h2>

### Description

Extracts n-grams from the input sequence and save them as a vector.

### Parameters

[Inputs]

One input

data: tensor of type int32 or int64.

[Outputs]

One output

y: tensor of type float.

[Attributes]

max_gram_length: int. Maximum n-gram length.

max_skip_count: int. Maximum number of items to be skipped when constructing an n-gram from data.

min_gram_length: int. Minimum n-gram length.

mode: string. The weighting criteria. It can be "TF" (term frequency), "IDF" (inverse document frequency), or "TFIDF" (the combination of TF and IDF).

ngram_counts: list of ints. The starting indexes of n-grams in pool. It is useful when determining the boundary between two consecutive collections of n-grams.

ngram_indexes: list of ints. The i-th element in ngram_indexes indicates the coordinate of the i-th n-gram in the output tensor.

pool_int64s: list of ints, indicating n-grams learned from the training set. This attribute and pool_strings are mutually exclusive.

pool_strings: list of strings. Has the same meaning as pool_int64s.

weights: list of floats. Stores the weight of each n-gram in pool.

### ONNX Opset Support

Opset v9/v10/v11/ v12/v13

<h2 id="Tilemd">Tile</h2>

### Description

Constructs a tensor by tiling a given tensor.

### Parameters 

[Inputs]

Two inputs

x: tensor

repeats: 1D tensor of type int64. Has the same size as the number of dimensions in x.

[Outputs]

One output

y: tensor of the identical type and dimension as the input. output_dim[i] = input_dim[i] * repeats[i]

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="ThresholdedRelumd">ThresholdedRelu</h2>

### Description

When x > alpha, y = x; otherwise, y = 0.

### Parameters 

[Inputs]

One input

x: tensor of type float16 or float32.

[Outputs]

One output

y: tensor of the same data type and shape as input x.

[Attributes]

alpha: float, indicating the threshold. Defaults to 1.0.

### ONNX Opset Support

Opset v10/v11/v12/v13

<h2 id="TopKmd">TopK</h2>

### Description

Retrieves the top-K largest or smallest elements along a specified axis.

### Parameters 

[Inputs]

Two inputs

x: tensor of type float16 or float32.

k: tensor of type int64.

[Outputs]

Two outputs

Values: tensor containing top K values from the input tensor.

Indexes: tensor containing the corresponding input tensor indices for the top K values.

[Attributes]

axis: int. The dimension on which to do the sort. Defaults to –1.

largest: int. Whether to return the top-K largest or smallest elements. Defaults to 1.

sorted: int. Whether to return the elements in sorted order. Defaults to 1.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Transposemd">Transpose</h2>

### Description

Transposes the input.

### Parameters 

[Inputs]

data: tensor. Must be one of the following types: float16, float32, int8, int16, int32, int64, uint8, uint16, uint32, uint64.

[Outputs]

transposed: tensor after transposition.

[Attributes]

perm: (required) list of integers, for the dimension sequence of data.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Padmd">Pad</h2>

### Description

Pads a tensor.

### Parameters 

[Inputs]

Two inputs

x: tensor of type float16, float32, or int32.

pads: tensor of type int32 or int64.

constant_value: optional. Defaults to 0, an empty string, or False. If the selected mode is constant, the scalar value is used.

[Outputs]

One output

y: tensor. Has an identical data type to that of input x.

[Attributes]

mode: str type. The following modes are supported: constant, reflect, and edge.

[Restrictions]

If the value of mode is constant, the value of constant_value can only be 0.

### ONNX Opset Support

Opset v11

<h2 id="Powmd">Pow</h2>

### Description

Computes x1 to the x2th power.

### Parameters 

[Inputs]

Two inputs

x1: tensor of type float16, float32, double, int32, int8, or uint8.

x2: tensor. Has an identical data type to that of input x1.

[Outputs]

One output

y: tensor. Has an identical data type to that of x1.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Unsqueezemd">Unsqueeze</h2>

### Description

Inserts single-dimensional entries to the shape of an input tensor.

### Parameters 

[Inputs]

One input

x: tensor of type uint8, uint16, uint32, int8, int16, int32, float16, or float32.

[Outputs]

One output

y: tensor. Has an identical data type to that of input x.

[Attributes]

axes: list of integers indicating the dimensions to be inserted. Accepted range is [–input_rank, input_rank](inclusive) where r = rank(x).

### ONNX Opset Support

Opset v8/v9/10/v11/v12

<h2 id="Xormd">Xor</h2>

### Description

Computes the element-wise logical XOR of the given input tensors.

### Parameters 

[Inputs]

Two inputs

a: tensor of type bool.

b: tensor of type bool.

[Outputs]

c: tensor of type bool.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13

<h2 id="Wheremd">Where</h2>

### Description

Returns elements chosen from x or y depending on condition.

### Parameters 

[Inputs]

Three inputs

condition: bool.

x: tensor of type float16, float32, int8, int32, or uint8. Elements from which to choose when condition is true.

y: tensor. Has an identical data type to that of x. Elements from which to choose when condition is false.

[Outputs]

Tensor that has an identical data type to that of input x.

### ONNX Opset Support

Opset v8/v9/v10/v11/v12/v13
